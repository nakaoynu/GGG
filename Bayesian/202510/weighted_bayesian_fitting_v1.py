# weighted_bayesian_fitting_2param_gamma.py - 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã‚’ç”¨ã„ãŸé‡ã¿ä»˜ããƒ™ã‚¤ã‚ºæ¨å®š
#
# ã€é‡è¦ã€‘NUTSã‚µãƒ³ãƒ—ãƒ©ãƒ¼ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã¤ã„ã¦:
#   - config.ymlã§ nuts_sampler: "numpyro" ã‚’æŒ‡å®šã—ãŸå ´åˆã€
#     numpyroã¨jaxã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™:
#       pip install numpyro jax jaxlib
#   - numpyroã¯é«˜é€Ÿã§ã™ãŒã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªã„å ´åˆã¯
#     config.ymlã‹ã‚‰ nuts_sampler è¡Œã‚’å‰Šé™¤ã™ã‚Œã° PyMCæ¨™æº–ã®NUTSãŒä½¿ç”¨ã•ã‚Œã¾ã™
#
# ã€å†ç¾æ€§ã«ã¤ã„ã¦ã€‘(2025-11-06è¿½åŠ ):
#   - config.ymlã® mcmc.random_seed ã§ã‚·ãƒ¼ãƒ‰å€¤ã‚’è¨­å®šã™ã‚‹ã¨çµæœãŒå†ç¾å¯èƒ½ã«ãªã‚Šã¾ã™
#   - random_seed: 42 ãªã©ã®æ•´æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„
#   - ãƒãƒ«ãƒãƒã‚§ãƒ¼ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ã‚‚ã€å„ãƒã‚§ãƒ¼ãƒ³ã«ç•°ãªã‚‹ã‚·ãƒ¼ãƒ‰ãŒè‡ªå‹•å‰²ã‚Šå½“ã¦ã•ã‚Œã€
#     åŒã˜random_seedã‹ã‚‰ã®å®Ÿè¡Œã¯å¸¸ã«åŒã˜çµæœã‚’ç”Ÿæˆã—ã¾ã™
#
# ã€gammaãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›´ç‚¹ã€‘ (2025-11-14):
#   - æ¸©åº¦ä¾å­˜æ€§ã‚’å‰Šé™¤
#   - 7è¦ç´ ã®gammaã‚’2ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆlog_gamma_min, log_gamma_otherï¼‰ã§è¨˜è¿°
#   - gammaé…åˆ—ã¯ [gamma_min, gamma_other, gamma_other, ...] ã¨ãªã‚‹
#   - ç›®çš„: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å‰Šæ¸›ã—ã€åæŸæ€§ã‚’å‘ä¸Šã•ã›ã‚‹

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pymc as pm
import arviz as az
import pytensor.tensor as pt
from pytensor.graph.op import Op
import os
import pathlib
import re
import warnings
import yaml
import datetime
from typing import List, Dict, Any, Tuple, Optional, Union
from scipy.signal import find_peaks, peak_widths
from scipy.optimize import curve_fit

# æ•°å€¤è¨ˆç®—ã®è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore', category=RuntimeWarning)
np.seterr(all='ignore')  # NumPyã®è­¦å‘Šã‚‚æŠ‘åˆ¶

# --- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ©Ÿèƒ½ ---
def load_config(config_path: Optional[Union[str, pathlib.Path]] = None) -> Dict[str, Any]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«(YAML)ã‚’èª­ã¿è¾¼ã¿ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ãƒãƒ¼ã‚¸ã™ã‚‹"""
    if config_path is None:
        config_path = pathlib.Path(__file__).parent / "config.yml" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šå€¤
    default_config = {
        'file_paths': {
            'data_file': "C:\\Users\\taich\\OneDrive - YNU(ynu.jp)\\master\\ç£æ€§\\GGG\\Programs\\corrected_exp_datasets\\Corrected_Transmittance_Temperature.xlsx",
            'sheet_name': "Corrected Data",
            'results_parent_dir': "analysis_results_2param_gamma" # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’å¤‰æ›´
        },
        'execution': {
            'use_gpu': False
        },
        'physical_parameters': {
            'B_fixed': 9.0,
            'd_fixed': 157.8e-6,
            's': 3.5,
            'N_spin': 1.9386e+28,
            'initial_values': {
                'eps_bg': 14.20,
                'g_factor': 2.003147,
                'B4': 0.000576,
                'B6': 0.000050,
                'gamma': 0.11e12,
                'a_scale': 0.604971
            }
        },
        'analysis_settings': {
            'temperature_columns': ['4K', '30K', '100K', '300K'],
            'low_freq_cutoff': 0.361505,
            'high_freq_cutoff': 0.45,
            'weight_settings': {
                'peak_height_threshold': 0.05,
                'peak_prominence_threshold': 0.05,
                'peak_distance': 10,
                'lp_up_peak_weight': 1.0,
                'between_peaks_weight': 0.1,
                'high_freq_peak_weight': 1.0,
                'background_weight': 0.0
            }
        },
        'mcmc': {
            'draws': 4000,
            'tune': 2000,
            'chains': 4,
            'target_accept': 0.90,
            'init': "adapt_diag",
            'max_iterations': 2 # (ä¾‹ï¼šåå¾©å›æ•°ã‚’è¨­å®š)
        },
        'bayesian_priors': {
            'magnetic_parameters': {
                'a_scale': {'distribution': 'HalfNormal', 'sigma': 1.0},
                'g_factor': {'distribution': 'Normal', 'sigma': 0.1},
                'B4': {'distribution': 'Normal', 'sigma': 0.001},
                'B6': {'distribution': 'Normal', 'sigma': 0.0001}
            },
            'with_prior_info': {
                'a_scale': {'distribution': 'Normal', 'sigma': 0.2},
                'g_factor': {'distribution': 'Normal', 'sigma': 0.05},
                'B4': {'distribution': 'Normal', 'sigma': 0.0005},
                'B6': {'distribution': 'Normal', 'sigma': 0.0001}
            },
            # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘gammaã®äº‹å‰åˆ†å¸ƒã‚’2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›´ â–¼â–¼â–¼
            'gamma_parameters': {
                'log_gamma_min': {'distribution': 'Normal', 'sigma': 1.0},
                'log_gamma_other': {'distribution': 'Normal', 'sigma': 1.0}
            },
            'noise_parameters': {
                'sigma': {'distribution': 'HalfNormal', 'sigma': 0.05}
            }
        }
    }
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            user_config = yaml.safe_load(f)
        
        # å†å¸°çš„ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’æ›´æ–°
        def merge_dict(default, user):
            for key, value in user.items():
                if key in default and isinstance(default[key], dict) and isinstance(value, dict):
                    merge_dict(default[key], value) # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¾æ›¸ã‚’å†å¸°çš„ã«.yamlãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã§æ›´æ–°
                else:
                    default[key] = value
        
        merge_dict(default_config, user_config)
        print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« '{config_path}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        
    except FileNotFoundError:
        print(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« '{config_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    except Exception as e:
        print(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    
    return default_config

# --- çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ ---
def create_results_directory(config: Dict[str, Any]) -> pathlib.Path:
    """å®Ÿè¡Œæ—¥æ™‚ã‚’å«ã‚€ä¸€æ„ã®çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    results_parent = config['file_paths']['results_parent_dir']
    results_dir = pathlib.Path(__file__).parent / results_parent / f"run_{timestamp}"
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # ä½¿ç”¨ã—ãŸè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ã‚³ãƒ”ãƒ¼
    config_backup_path = results_dir / "config_used.yml"
    with open(config_backup_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"ğŸ“ çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {results_dir.resolve()}")
    return results_dir

# --- 0. ç’°å¢ƒè¨­å®š ---
print("--- 0. ç’°å¢ƒè¨­å®šã‚’é–‹å§‹ã—ã¾ã™ ---")

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆconfig.ymlã‹ã‚‰å¤‰æ›´ã—ãŸã„å ´åˆã¯ã“ã“ã‚’ç·¨é›†ï¼‰
CONFIG = load_config(config_path=pathlib.Path(__file__).parent / "config_v1.yml")

# å†ç¾æ€§ç¢ºä¿ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰è¨­å®š (2025-11-06è¿½åŠ )
# NumPyä¹±æ•°ç”Ÿæˆå™¨ã‚’å›ºå®šï¼ˆãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚„æœ€é©åŒ–ã§ä½¿ç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
if 'random_seed' in CONFIG['mcmc']:
    RANDOM_SEED = CONFIG['mcmc']['random_seed']
    np.random.seed(RANDOM_SEED)
    print(f"ğŸ² ä¹±æ•°ã‚·ãƒ¼ãƒ‰è¨­å®š: {RANDOM_SEED} (NumPy & PyMC)")
else:
    RANDOM_SEED = None
    print("â„¹ï¸ ä¹±æ•°ã‚·ãƒ¼ãƒ‰æœªè¨­å®šï¼ˆçµæœã¯å®Ÿè¡Œã”ã¨ã«å¤‰ã‚ã‚Šã¾ã™ï¼‰")

# GPUåˆ©ç”¨è¨­å®šï¼ˆPyTensoræ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œãƒ»å®‰å…¨ç‰ˆï¼‰
USE_GPU = CONFIG['execution']['use_gpu']
print("ğŸ”§ PyTensorè¨­å®šã‚’åˆæœŸåŒ–ä¸­...")

# PyTensorã®ç’°å¢ƒå¤‰æ•°ã¯å¿…ãšimportå‰ã«è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹
if USE_GPU:
    try:
        import cupy
        print("âœ… CuPy ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
        # æ–°ã—ã„PyTensorã§ã®GPUè¨­å®šã®è©¦è¡Œ
        try:
            os.environ['PYTENSOR_FLAGS'] = 'device=cuda,floatX=float64'
            print("ğŸš€ GPU (CUDA) è¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸã€‚")
        except:
            print("âš ï¸ CUDAè¨­å®šã«å¤±æ•—ã€‚CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            os.environ['PYTENSOR_FLAGS'] = 'device=cpu,floatX=float64'
    except ImportError:
        print("âš ï¸ CuPy ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        os.environ['PYTENSOR_FLAGS'] = 'device=cpu,floatX=float64'
else:
    print("ğŸ’» CPUè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    os.environ['PYTENSOR_FLAGS'] = 'device=cpu,floatX=float64'

try:
    import japanize_matplotlib
except ImportError:
    print("è­¦å‘Š: japanize_matplotlib ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

plt.rcParams['figure.dpi'] = 120

# çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ã®ã¿ä½œæˆï¼‰
RESULTS_DIR = None

# --- 1. ç‰©ç†å®šæ•°ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¡ä»¶ ---
print("--- 1. ç‰©ç†å®šæ•°ã¨åˆæœŸå€¤ã‚’è¨­å®šã—ã¾ã™ ---")
kB = 1.380649e-23; muB = 9.274010e-24; hbar = 1.054571e-34
c = 299792458; mu0 = 4.0 * np.pi * 1e-7

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
s = CONFIG['physical_parameters']['s']
N_spin = CONFIG['physical_parameters']['N_spin']
B_FIXED = CONFIG['physical_parameters']['B_fixed']
d_fixed = CONFIG['physical_parameters']['d_fixed']

# åˆæœŸå€¤ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
initial_values = CONFIG['physical_parameters']['initial_values']
eps_bg_init = float(initial_values['eps_bg'])
B4_init = float(initial_values['B4'])
B6_init = float(initial_values['B6'])
gamma_init = float(initial_values['gamma']) # 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã®äº‹å‰åˆ†å¸ƒã®å¹³å‡å€¤ã¨ã—ã¦ä½¿ç”¨
a_scale_init = float(initial_values['a_scale'])
g_factor_init = float(initial_values['g_factor'])

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
DATA_FILE_PATH = CONFIG['file_paths']['data_file']
DATA_SHEET_NAME = CONFIG['file_paths']['sheet_name']

# è§£æè¨­å®š
TEMPERATURE_COLUMNS = CONFIG['analysis_settings']['temperature_columns']
LOW_FREQUENCY_CUTOFF = CONFIG['analysis_settings']['low_freq_cutoff']
HIGH_FREQUENCY_CUTOFF = CONFIG['analysis_settings']['high_freq_cutoff']

# MCMCã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®š
MCMC_CONFIG = CONFIG['mcmc']

# --- ç‰©ç†ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•° ---

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
class HamiltonianCache:
    """ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³è¨ˆç®—ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ã‚¹ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰"""
    def __init__(self):
        self._cache = {}
    
    def get_hamiltonian_cached(self, B_ext_z: float, g_factor: float, B4: float, B6: float) -> np.ndarray:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã‚’å–å¾—ï¼ˆåŒä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®é‡è¤‡è¨ˆç®—ã‚’å›é¿ï¼‰"""
        key = (round(B_ext_z, 6), round(g_factor, 6), round(B4, 8), round(B6, 8))
        if key not in self._cache:
            self._cache[key] = get_hamiltonian(B_ext_z, g_factor, B4, B6)
        return self._cache[key]
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self._cache.clear()

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_hamiltonian_cache = HamiltonianCache()

def get_hamiltonian_cached(B_ext_z: float, g_factor: float, B4: float, B6: float) -> np.ndarray:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³è¨ˆç®—ã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯é–¢æ•°"""
    return _hamiltonian_cache.get_hamiltonian_cached(B_ext_z, g_factor, B4, B6)

# äº‹å‰è¨ˆç®—ã•ã‚ŒãŸå›ºå®šã‚¬ãƒ³ãƒé…åˆ—ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡æœ€é©åŒ–ï¼‰
# â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®gamma_initå€¤ã§åˆæœŸåŒ– â–¼â–¼â–¼
_FIXED_GAMMA_ARRAY = np.full(7, gamma_init)

def normalize_gamma_array(gamma_input, target_length: int = 7) -> np.ndarray:
    """
    ã‚¬ãƒ³ãƒé…åˆ—ã®æ­£è¦åŒ–ã¨å‹å®‰å…¨æ€§ã‚’ç¢ºä¿ï¼ˆå¯å¤‰é•·å¯¾å¿œç‰ˆï¼‰
    
    Args:
        gamma_input: ã‚¹ã‚«ãƒ©ãƒ¼ã€é…åˆ—ã€ã¾ãŸã¯PyTensorãƒ†ãƒ³ã‚½ãƒ«
        target_length: ç›®æ¨™é…åˆ—é•·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ7ï¼‰
    """
    if np.isscalar(gamma_input):
        return np.full(target_length, gamma_input)
    elif hasattr(gamma_input, 'ndim') and gamma_input.ndim == 0:
        return np.full(target_length, float(gamma_input))
    elif hasattr(gamma_input, '__len__'):
        gamma_array = np.array(gamma_input)
        if len(gamma_array) == target_length:
            return gamma_array
        elif len(gamma_array) > target_length:
            return gamma_array[:target_length]
        else:
            # çŸ­ã„å ´åˆã¯æœ€å¾Œã®å€¤ã§åŸ‹ã‚ã‚‹ï¼ˆedge modeï¼‰
            return np.pad(gamma_array, (0, target_length - len(gamma_array)), 'edge')
    else:
        # PyTensorãƒ†ãƒ³ã‚½ãƒ«ãªã©ã® .item() å‘¼ã³å‡ºã—
        try:
            return np.full(target_length, gamma_input.item())
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return np.full(target_length, gamma_init)


def get_eps_bg_initial_values_and_bounds(temperature: float) -> Tuple[List[float], Tuple[float, float]]:
    """æ¸©åº¦ä¾å­˜eps_bgåˆæœŸå€¤ã¨å¢ƒç•Œå€¤ã®å–å¾—ï¼ˆçµ±åˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ï¼‰"""
    eps_bg_init_val = eps_bg_init # ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‹ã‚‰èª­ã¿è¾¼ã¿
    if temperature <= 10:
        # ä½æ¸©ã§ã¯ä½ã‚ã®åˆæœŸå€¤ã‹ã‚‰é–‹å§‹ï¼ˆãƒ•ã‚©ãƒãƒ³ã®å‡çµåŠ¹æœï¼‰
        initial_eps_bg_values = [eps_bg_init_val * 0.85, eps_bg_init_val * 0.90, eps_bg_init_val * 0.95, eps_bg_init_val,
                                13.0, 12.5, 12.8, 13.2, 13.5, 14.0]
        bounds_eps_bg = (11.0, 16.0)
    elif temperature <= 100:
        # ä¸­é–“æ¸©åº¦ã§ã¯æ¨™æº–çš„ãªåˆæœŸå€¤
        initial_eps_bg_values = [eps_bg_init_val * 0.98, eps_bg_init_val, eps_bg_init_val * 1.02, eps_bg_init_val * 1.05,
                                13.8, 14.0, 14.2, 13.5, 14.5, 13.2]
        bounds_eps_bg = (11.5, 16.5)
    else:
        # é«˜æ¸©ã§ã¯é«˜ã‚ã®åˆæœŸå€¤ã‹ã‚‰é–‹å§‹ï¼ˆãƒ•ã‚©ãƒãƒ³ã®æ´»æ€§åŒ–ï¼‰
        initial_eps_bg_values = [eps_bg_init_val * 1.05, eps_bg_init_val * 1.10, eps_bg_init_val * 1.15, eps_bg_init_val,
                                14.5, 15.0, 15.5, 14.0, 16.0, 13.8]
        bounds_eps_bg = (12.0, 17.0)
    return initial_eps_bg_values, bounds_eps_bg

def get_hamiltonian(B_ext_z: float, g_factor: float, B4: float, B6: float) -> np.ndarray:
    """ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã‚’è¨ˆç®—ã™ã‚‹"""
    m_values = np.arange(s, -s - 1, -1)
    Sz = np.diag(m_values)
    O40 = 60 * np.diag([7, -13, -3, 9, 9, -3, -13, 7])
    X_O44 = np.zeros((8, 8)); X_O44[3, 7], X_O44[4, 0] = np.sqrt(35), np.sqrt(35); X_O44[2, 6], X_O44[5, 1] = 5 * np.sqrt(3), 5 * np.sqrt(3)
    O44 = 12 * (X_O44 + X_O44.T)
    O60 = 1260 * np.diag([1, -5, 9, -5, -5, 9, -5, 1])
    X_O64 = np.zeros((8, 8)); X_O64[3, 7], X_O64[4, 0] = 3 * np.sqrt(35), 3 * np.sqrt(35); X_O64[2, 6], X_O64[5, 1] = -7 * np.sqrt(3), -7 * np.sqrt(3)
    O64 = 60 * (X_O64 + X_O64.T)
    H_cf = (B4 * kB) * (O40 + 5 * O44) + (B6 * kB) * (O60 - 21 * O64)
    H_zee = g_factor * muB * B_ext_z * Sz
    return H_cf + H_zee

def calculate_susceptibility(omega_array: np.ndarray, H: np.ndarray, T: float, gamma_array: np.ndarray) -> np.ndarray:
    """ç£æ°—æ„Ÿå—ç‡ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆæ¸©åº¦ä¾å­˜gammaå¯¾å¿œãƒ»å‹å®‰å…¨ç‰ˆï¼‰"""
    
    # çµ±åˆã•ã‚ŒãŸã‚¬ãƒ³ãƒé…åˆ—æ­£è¦åŒ–é–¢æ•°ã‚’ä½¿ç”¨ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
    # (å…¥åŠ›gamma_arrayã¯PyMCãƒ¢ãƒ‡ãƒ«å´ã§7è¦ç´ ã«æ•´å½¢ã•ã‚Œã¦æ¸¡ã•ã‚Œã‚‹)
    gamma_array = normalize_gamma_array(gamma_array)

    # eighã¯å›ºæœ‰å€¤ã‚’æ˜‡é †ã§è¿”ã™ (E0, E1, ..., E7)
    eigenvalues, _ = np.linalg.eigh(H)
    eigenvalues -= np.min(eigenvalues)
    
    # æ•°å€¤çš„å®‰å®šæ€§ã®ãŸã‚ã®ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
    eigenvalues = np.clip(eigenvalues / (kB * T), -700, 700)
    
    Z = np.sum(np.exp(-eigenvalues))
    populations = np.exp(-eigenvalues) / Z
    
    # delta_E[0] = E1-E0 (æœ€ä½æ¬¡é·ç§»), ..., delta_E[6] = E7-E6
    delta_E = (eigenvalues[1:] - eigenvalues[:-1]) * kB * T  # å…ƒã®å˜ä½ã«æˆ»ã™
    delta_pop = populations[1:] - populations[:-1]
    
    # ç„¡åŠ¹ãªå€¤ã‚’ãƒã‚§ãƒƒã‚¯
    valid_mask = np.isfinite(delta_E) & (np.abs(delta_E) > 1e-30)
    if not np.any(valid_mask):
        return np.zeros_like(omega_array, dtype=complex)
    
    omega_0 = delta_E / hbar
    m_vals = np.arange(s, -s, -1) # 7è¦ç´ 
    transition_strength = (s + m_vals) * (s - m_vals + 1) # 7è¦ç´ 
    
    # === ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›: gamma_arrayãŒdelta_Eã¨åŒã˜æ¬¡å…ƒã‚’æŒã¤ã‚ˆã†ã«èª¿æ•´ ===
    if len(gamma_array) != len(delta_E):
        # print(f"  Gamma/Delta_E é•·ã•ä¸ä¸€è‡´: gamma={len(gamma_array)}, delta_E={len(delta_E)}")
        if len(gamma_array) > len(delta_E):
            gamma_array = gamma_array[:len(delta_E)]
        else:
            gamma_array = np.pad(gamma_array, (0, len(delta_E) - len(gamma_array)), 'edge')
    
    # æ•°å€¤çš„å®‰å®šæ€§ã®å‘ä¸Š
    numerator = delta_pop * transition_strength
    
    # ç„¡åŠ¹ãªå€¤ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    finite_mask = np.isfinite(numerator) & np.isfinite(omega_0) & np.isfinite(gamma_array)
    numerator = numerator[finite_mask]
    omega_0_filtered = omega_0[finite_mask]
    gamma_filtered = gamma_array[finite_mask]
    
    if len(numerator) == 0:
        return np.zeros_like(omega_array, dtype=complex)
    
    # denominatorã®è¨ˆç®—ã‚’å®‰å…¨ã«å®Ÿè¡Œ
    chi_array = np.zeros_like(omega_array, dtype=complex)
    for i, omega in enumerate(omega_array):
        if not np.isfinite(omega):
            continue
        denominator = omega_0_filtered - omega - 1j * gamma_filtered
        # éå¸¸ã«å°ã•ã„å€¤ã‚’é¿ã‘ã‚‹
        denominator[np.abs(denominator) < 1e-20] = 1e-20 + 1j * 1e-20
        chi_array[i] = np.sum(numerator / denominator)
    
    return -chi_array

def calculate_normalized_transmission(omega_array: np.ndarray, mu_r_array: np.ndarray, d: float, eps_bg: float) -> np.ndarray:
    """æ­£è¦åŒ–é€éç‡ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆæ”¹è‰¯ç‰ˆï¼šæ•°å€¤å®‰å®šæ€§ã¨ãƒ”ãƒ¼ã‚¯ä½ç½®ç²¾åº¦ã®å‘ä¸Šï¼‰"""
    # å…¥åŠ›å€¤ã®æ¤œè¨¼ã¨å®‰å…¨ãªå‡¦ç†
    eps_bg = max(eps_bg, 0.1)  # æœ€å°å€¤ã‚’è¨­å®š
    d = max(d, 1e-6)  # æœ€å°å€¤ã‚’è¨­å®š
    
    # è¤‡ç´ å±ˆæŠ˜ç‡ã¨ impedance ã®è¨ˆç®—
    mu_r_safe = np.where(np.isfinite(mu_r_array), mu_r_array, 1.0)
    eps_mu_product = eps_bg * mu_r_safe
    eps_mu_product = np.where(eps_mu_product.real > 0, eps_mu_product, 0.1 + 1j * eps_mu_product.imag)
    
    n_complex = np.sqrt(eps_mu_product + 0j)
    impe = np.sqrt(mu_r_safe / eps_bg + 0j)
    
    # æ³¢é•·è¨ˆç®—ï¼ˆã‚¼ãƒ­å‘¨æ³¢æ•°ã‚’é¿ã‘ã‚‹ï¼‰
    lambda_0 = np.full_like(omega_array, np.inf, dtype=float)
    nonzero_mask = omega_array > 1e-12
    lambda_0[nonzero_mask] = (2 * np.pi * c) / omega_array[nonzero_mask]
    
    # ä½ç›¸è¨ˆç®—ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢ï¼‰
    delta = 2 * np.pi * n_complex * d / lambda_0
    delta = np.clip(delta.real, -700, 700) + 1j * np.clip(delta.imag, -700, 700)
    
    # é€éç‡è¨ˆç®—
    numerator = 4 * impe
    exp_pos = np.exp(-1j * delta)
    exp_neg = np.exp(1j * delta)
    
    denominator = (1 + impe)**2 * exp_pos - (1 - impe)**2 * exp_neg
    
    # åˆ†æ¯ãŒã‚¼ãƒ­ã«è¿‘ã„å ´åˆã®å‡¦ç†
    safe_mask = np.abs(denominator) > 1e-15
    t = np.zeros_like(denominator, dtype=complex)
    t[safe_mask] = numerator[safe_mask] / denominator[safe_mask]
    
    transmission = np.abs(t)**2
    
    # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã€ç•°å¸¸å€¤ã‚’é™¤å»
    transmission = np.where(np.isfinite(transmission), transmission, 0.0)
    transmission = np.clip(transmission, 0, 2)  # ç‰©ç†çš„ã«æ„å‘³ã®ã‚ã‚‹ç¯„å›²ã«åˆ¶é™
    
    # æ­£è¦åŒ–
    min_trans, max_trans = np.min(transmission), np.max(transmission)
    if max_trans > min_trans and np.isfinite(max_trans) and np.isfinite(min_trans):
        return (transmission - min_trans) / (max_trans - min_trans)
    else:
        return np.full_like(transmission, 0.5)

# â–¼â–¼â–¼ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œã®é‡ã¿ä»˜ã‘é–¢æ•° â–¼â–¼â–¼
def create_frequency_weights(dataset: Dict[str, Any], analysis_settings: Dict[str, Any]) -> np.ndarray:
    """
    å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®ãƒ”ãƒ¼ã‚¯ç‰¹æ€§ã«åŸºã¥ãã€å°¤åº¦é–¢æ•°ã®ãŸã‚ã®é‡ã¿é…åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä½¿ç”¨ã—ã¦ãƒ”ãƒ¼ã‚¯æ¤œå‡ºã¨é‡ã¿ä»˜ã‘ã‚’è¡Œã†ã€‚
    
    Args:
        dataset: å‘¨æ³¢æ•°ã¨é€éç‡ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸
        analysis_settings: è§£æè¨­å®šï¼ˆweight_settings ã¨ high_freq_cutoff ã‚’å«ã‚€ï¼‰
    """
    # è¨­å®šå€¤ã‚’å–å¾—
    weight_config = analysis_settings['weight_settings']
    high_freq_cutoff = analysis_settings['high_freq_cutoff']
    
    freq = dataset['frequency']
    trans = dataset['transmittance_full']
    
    # ãƒ”ãƒ¼ã‚¯æ¤œå‡º (è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä½¿ç”¨)
    peaks, properties = find_peaks(trans,
                                   height=weight_config['peak_height_threshold'],
                                   prominence=weight_config['peak_prominence_threshold'],
                                   distance=weight_config['peak_distance'])
    
    if len(peaks) < 2:
        # ãƒ”ãƒ¼ã‚¯ãŒå°‘ãªã™ãã‚‹å ´åˆã¯ã€ä½å‘¨æ³¢é ˜åŸŸå…¨ä½“ã«å‡ä¸€ãªé‡ã¿ã‚’ä»˜ã‘ã‚‹
        weights = np.zeros_like(freq)
        low_freq_mask = freq < high_freq_cutoff
        weights[low_freq_mask] = 1.0
        return weights

    # å„ãƒ”ãƒ¼ã‚¯ã®åŠå€¤å¹…ã‚’è¨ˆç®—
    widths, _, left_ips, right_ips = peak_widths(trans, peaks, rel_height=0.5)
    
    # å‘¨æ³¢æ•°å˜ä½ã«å¤‰æ›
    left_freq = np.interp(left_ips, np.arange(len(freq)), freq)
    right_freq = np.interp(right_ips, np.arange(len(freq)), freq)

    # é‡ã¿é…åˆ—ã®åˆæœŸåŒ–
    weights = np.full_like(freq, weight_config['background_weight'])

    # LPã¨UPã‚’ç‰¹å®šï¼ˆãƒ—ãƒ­ãƒŸãƒãƒ³ã‚¹ã§ã‚½ãƒ¼ãƒˆï¼‰
    low_freq_peaks = peaks[freq[peaks] < high_freq_cutoff]
    if len(low_freq_peaks) >= 2:
        # ãƒ—ãƒ­ãƒŸãƒãƒ³ã‚¹ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½2ã¤ã‚’å–å¾—
        peak_prominences = properties['prominences'][freq[peaks] < high_freq_cutoff]
        sorted_indices = np.argsort(peak_prominences)[::-1]  # é™é †ã‚½ãƒ¼ãƒˆ

        lp_idx_in_all_peaks = np.where(peaks == low_freq_peaks[sorted_indices[0]])[0][0] #å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦sorted_indicesã‚’æ±ºã‚ã‚‹â†’LPã¨UPã‚’æ±ºå®š
        up_idx_in_all_peaks = np.where(peaks == low_freq_peaks[sorted_indices[1]])[0][0]

        # ãƒ”ãƒ¼ã‚¯é–“é ˜åŸŸã®é‡ã¿ä»˜ã‘ï¼ˆåŠå€¤å¹…ã®å¤–å´ã®é–“ï¼‰
        # å …ç‰¢æ€§ã®ãŸã‚ã€å‘¨æ³¢æ•°ã®å¤§å°é–¢ä¿‚ã‚’è‡ªå‹•åˆ¤å®š
        lp_fwhm_right_freq = right_freq[lp_idx_in_all_peaks]
        up_fwhm_left_freq = left_freq[up_idx_in_all_peaks]
        
        lower_bound = np.minimum(lp_fwhm_right_freq, up_fwhm_left_freq)
        upper_bound = np.maximum(lp_fwhm_right_freq, up_fwhm_left_freq)
        between_mask = (freq >= lower_bound) & (freq <= upper_bound)
        weights[between_mask] = weight_config['between_peaks_weight']
        
        # LPã¨UPã®åŠå€¤å¹…é ˜åŸŸã«é‡ã¿ã‚’ä»˜ä¸
        lp_fwhm_mask = (freq >= left_freq[lp_idx_in_all_peaks]) & (freq <= right_freq[lp_idx_in_all_peaks])
        up_fwhm_mask = (freq >= left_freq[up_idx_in_all_peaks]) & (freq <= right_freq[up_idx_in_all_peaks])
        weights[lp_fwhm_mask] = weight_config['lp_up_peak_weight']
        weights[up_fwhm_mask] = weight_config['lp_up_peak_weight']
        
    # é«˜å‘¨æ³¢ã®å…±æŒ¯å™¨ãƒ¢ãƒ¼ãƒ‰ã«ã‚‚é‡ã¿ã‚’ä»˜ä¸
    high_freq_peak_indices = np.where(freq[peaks] >= high_freq_cutoff)[0]
    for idx_in_all_peaks in high_freq_peak_indices:
        fwhm_mask = (freq >= left_freq[idx_in_all_peaks]) & (freq <= right_freq[idx_in_all_peaks])
        weights[fwhm_mask] = weight_config['high_freq_peak_weight']

    print(f"  æ¸©åº¦ {dataset['temperature']}K: é‡ã¿é…åˆ—ã‚’ç”Ÿæˆã€‚(å…¨ãƒ‡ãƒ¼ã‚¿æ•°ï¼š{len(freq)})\n"
          f"    - LP/UPãƒ”ãƒ¼ã‚¯ (é‡ã¿={weight_config['lp_up_peak_weight']}): {np.sum(weights == weight_config['lp_up_peak_weight'])} ç‚¹\n"
          f"    - LP-UPé–“ (é‡ã¿={weight_config['between_peaks_weight']}): {np.sum(weights == weight_config['between_peaks_weight'])} ç‚¹\n"
          f"    - é«˜å‘¨æ³¢ãƒ”ãƒ¼ã‚¯ (é‡ã¿={weight_config['high_freq_peak_weight']}): {np.sum(weights == weight_config['high_freq_peak_weight'])} ç‚¹")
    return weights

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°ç¾¤ ---
def load_all_full_range_data(file_path: str, sheet_name: str) -> List[Dict[str, Any]]:
    """å…¨ç¯„å›²ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆeps_bgãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ç”¨ã§ã¯ãªã„ï¼‰"""
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name, header=0)
    except Exception as e:
        raise FileNotFoundError(f"Excelãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“: {e}")
    
    freq_col = 'Frequency (THz)'
    df[freq_col] = pd.to_numeric(df[freq_col], errors='coerce')
    temp_cols = TEMPERATURE_COLUMNS
    
    all_datasets_full = []
    
    for col in temp_cols:
        if col not in df.columns:
            print(f"è­¦å‘Š: åˆ— '{col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
            
        temp_value = float(col.replace('K', ''))
        df_clean = df[[freq_col, col]].dropna()
        freq, trans = df_clean[freq_col].values.astype(np.float64), df_clean[col].values.astype(np.float64)
        
        # å…¨ç¯„å›²ãƒ‡ãƒ¼ã‚¿
        all_datasets_full.append({
            'temperature': temp_value, 
            'b_field': B_FIXED, 
            'frequency': freq, 
            'transmittance_full': trans, # æ­£è¦åŒ–ã•ã‚Œã¦ã„ãªã„å…¨ãƒ‡ãƒ¼ã‚¿
            'omega': freq * 1e12 * 2 * np.pi
        })
    
    print(f"å…¨ç¯„å›²æ¸©åº¦ä¾å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(all_datasets_full)} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
    return all_datasets_full

def load_and_split_data_three_regions_temperature(file_path: str, sheet_name: str, 
                                                 low_cutoff: float = LOW_FREQUENCY_CUTOFF, 
                                                 high_cutoff: float = HIGH_FREQUENCY_CUTOFF) -> Dict[str, Any]:
    """æ¸©åº¦ä¾å­˜ãƒ‡ãƒ¼ã‚¿ã‚’1å›ã ã‘èª­ã¿è¾¼ã¿ã€ã™ã¹ã¦ã®å½¢å¼ã§æä¾›ã™ã‚‹çµ±ä¸€é–¢æ•°"""
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name, header=0)
    except Exception as e:
        raise FileNotFoundError(f"Excelãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“: {e}")
    
    freq_col = 'Frequency (THz)'
    df[freq_col] = pd.to_numeric(df[freq_col], errors='coerce')
    temp_cols = TEMPERATURE_COLUMNS
    
    # å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ä¸€åº¦ã«ä½œæˆ
    low_freq_datasets, mid_freq_datasets, high_freq_datasets = [], [], []
    all_datasets_full = []
    
    for col in temp_cols:
        if col not in df.columns:
            print(f"è­¦å‘Š: åˆ— '{col}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue
            
        temp_value = float(col.replace('K', ''))
        df_clean = df[[freq_col, col]].dropna()
        freq, trans = df_clean[freq_col].values.astype(np.float64), df_clean[col].values.astype(np.float64)
        
        # 3ã¤ã®é ˜åŸŸã«ãƒã‚¹ã‚¯ã‚’å®šç¾©
        low_mask = freq <= low_cutoff
        mid_mask = (freq > low_cutoff) & (freq < high_cutoff)
        high_mask = freq >= high_cutoff
        
        base_data = {'temperature': temp_value, 'b_field': B_FIXED}
        
        # ä½å‘¨æ³¢é ˜åŸŸ
        if np.any(low_mask):
            min_low, max_low = trans[low_mask].min(), trans[low_mask].max()
            trans_norm_low = (trans[low_mask] - min_low) / (max_low - min_low) if max_low > min_low else np.full_like(trans[low_mask], 0.5)
            low_freq_datasets.append({**base_data, 'frequency': freq[low_mask], 'transmittance': trans_norm_low, 'omega': freq[low_mask] * 1e12 * 2 * np.pi})
        
        # ä¸­é–“é ˜åŸŸ
        if np.any(mid_mask):
            min_mid, max_mid = trans[mid_mask].min(), trans[mid_mask].max()
            trans_norm_mid = (trans[mid_mask] - min_mid) / (max_mid - min_mid) if max_mid > min_mid else np.full_like(trans[mid_mask], 0.5)
            mid_freq_datasets.append({**base_data, 'frequency': freq[mid_mask], 'transmittance': trans_norm_mid, 'omega': freq[mid_mask] * 1e12 * 2 * np.pi})
        
        # é«˜å‘¨æ³¢é ˜åŸŸ
        if np.any(high_mask):
            min_high, max_high = trans[high_mask].min(), trans[high_mask].max()
            trans_norm_high = (trans[high_mask] - min_high) / (max_high - min_high) if max_high > min_high else np.full_like(trans[high_mask], 0.5)
            high_freq_datasets.append({**base_data, 'frequency': freq[high_mask], 'transmittance': trans_norm_high, 'omega': freq[high_mask] * 1e12 * 2 * np.pi})
        
        # å…¨ç¯„å›²ãƒ‡ãƒ¼ã‚¿
        all_datasets_full.append({**base_data, 'frequency': freq, 'transmittance_full': trans, 'omega': freq * 1e12 * 2 * np.pi})
    
    print(f"æ¸©åº¦ä¾å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:")
    print(f"  ä½å‘¨æ³¢é ˜åŸŸ [~, {low_cutoff}THz]: {len(low_freq_datasets)} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
    print(f"  ä¸­é–“é ˜åŸŸ [{low_cutoff}THz, {high_cutoff}THz]: {len(mid_freq_datasets)} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
    print(f"  é«˜å‘¨æ³¢é ˜åŸŸ [{high_cutoff}THz, ~]: {len(high_freq_datasets)} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
    print(f"  å…¨ç¯„å›²ãƒ‡ãƒ¼ã‚¿: {len(all_datasets_full)} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
    
    return {
        'low_freq': low_freq_datasets, 
        'mid_freq': mid_freq_datasets,
        'high_freq': high_freq_datasets,
        'all_full': all_datasets_full
    }

def fit_eps_bg_only_temperature(dataset: Dict[str, Any], 
                               fixed_params: Optional[Dict[str, Any]] = None,
                               bayesian_params: Optional[Dict[str, float]] = None) -> Dict[str, float]:
    """å„æ¸©åº¦ã§é«˜å‘¨æ³¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰eps_bgã®ã¿ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ï¼ˆä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å›ºå®šã¾ãŸã¯ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã‚’ä½¿ç”¨ï¼‰"""
    print(f"\n--- æ¸©åº¦ {dataset['temperature']} K ã®é«˜å‘¨æ³¢eps_bgãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚° ---")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å„ªå…ˆé †ä½ï¼šãƒ™ã‚¤ã‚ºæ¨å®šçµæœ > å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ > åˆæœŸå€¤
    if bayesian_params is not None:
        # ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã‚’ä½¿ç”¨ï¼ˆæ›´æ–°ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        effective_params = {
            'd': d_fixed,
            'g_factor': bayesian_params.get('g_factor', g_factor_init),
            'B4': bayesian_params.get('B4', B4_init),
            'B6': bayesian_params.get('B6', B6_init),
            'a_scale': bayesian_params.get('a_scale', a_scale_init)  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ã‚‚æ›´æ–°
        }
        print(f"  ğŸ”„ ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã‚’ä½¿ç”¨:")
        print(f"     g_factor = {effective_params['g_factor']:.6f}")
        print(f"     B4 = {effective_params['B4']:.6f}")
        print(f"     B6 = {effective_params['B6']:.6f}")
        print(f"     a_scale = {effective_params['a_scale']:.6f}")
        
        # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã‚‚ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã‹ã‚‰ä½¿ç”¨ â–¼â–¼â–¼
        if 'gamma_min' in bayesian_params and 'gamma_other' in bayesian_params:
            gamma_min_fit = bayesian_params['gamma_min']
            gamma_other_fit = bayesian_params['gamma_other']
            # [min, other, other, ...] ã®é †åº
            gamma_array_fit = np.array([gamma_min_fit] + [gamma_other_fit] * 6)
            print(f"     gamma_min = {gamma_min_fit:.3e}")
            print(f"     gamma_other = {gamma_other_fit:.3e}")
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            gamma_array_fit = _FIXED_GAMMA_ARRAY
            
    elif fixed_params is not None:
        effective_params = fixed_params
        gamma_array_fit = _FIXED_GAMMA_ARRAY
        print(f"  ğŸ“Œ å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆæœŸå€¤ã‚’ä½¿ç”¨
        effective_params = {
            'd': d_fixed,
            'g_factor': g_factor_init,
            'B4': B4_init,
            'B6': B6_init,
        }
        gamma_array_fit = _FIXED_GAMMA_ARRAY
        print(f"  ğŸ”° åˆæœŸå€¤ã‚’ä½¿ç”¨")
    
    def magnetic_cavity_model_eps_bg_only(freq_thz, eps_bg_fit):
        """eps_bgã®ã¿ã‚’å¤‰æ•°ã¨ã™ã‚‹é«˜å‘¨æ³¢é€éç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯æ›´æ–°ã•ã‚ŒãŸå€¤ã§å›ºå®šï¼‰"""
        try:
            omega = freq_thz * 1e12 * 2 * np.pi
            
            # æ›´æ–°ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å€¤ã‚’å–å¾—
            g_factor_fit = effective_params['g_factor']
            B4_fit = effective_params['B4']
            B6_fit = effective_params['B6']
            
            # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã¨ç£æ°—æ„Ÿå—ç‡ã®è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ï¼‰
            H = get_hamiltonian_cached(B_FIXED, g_factor_fit, B4_fit, B6_fit)
            
            # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã®gammaé…åˆ—ã‚’ä½¿ç”¨ â–¼â–¼â–¼
            chi_raw = calculate_susceptibility(omega, H, dataset['temperature'], gamma_array_fit)
            
            # ç£æ°—æ„Ÿå—ç‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆãƒ™ã‚¤ã‚ºæ¨å®šçµæœã®a_scaleã‚’ä½¿ç”¨ï¼‰
            if 'a_scale' in effective_params:
                # ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã®a_scaleã‚’ä½¿ç”¨
                G0 = effective_params['a_scale'] * mu0 * N_spin * (g_factor_fit * muB)**2 / (2 * hbar)
            else:
                # å¾“æ¥ã®æ–¹æ³•
                G0 = mu0 * N_spin * (g_factor_fit * muB)**2 / (2 * hbar)
            
            chi = G0 * chi_raw
            
            # H_formã§é€ç£ç‡ã‚’è¨ˆç®—
            mu_r = 1 + chi
            
            return calculate_normalized_transmission(omega, mu_r, d_fixed, eps_bg_fit)
        except Exception as e:
            print(f"    è­¦å‘Š: ãƒ¢ãƒ‡ãƒ«è¨ˆç®—ã‚¨ãƒ©ãƒ¼ {e}")
            return np.ones_like(freq_thz) * 0.5

    # è¤‡æ•°ã®åˆæœŸå€¤ã‚’è©¦è¡Œ
    success = False
    result = {}
    
    # æ¸©åº¦ä¾å­˜ã®åˆæœŸå€¤ã¨å¢ƒç•Œå€¤ã‚’å–å¾—
    initial_eps_bg_values, bounds_eps_bg = get_eps_bg_initial_values_and_bounds(dataset['temperature'])
    
    for attempt, initial_eps_bg in enumerate(initial_eps_bg_values):
        try:
            print(f"  è©¦è¡Œ {attempt + 1}: eps_bgåˆæœŸå€¤ = {initial_eps_bg:.3f}")
            
            popt, pcov = curve_fit(
                magnetic_cavity_model_eps_bg_only,
                dataset['frequency'],
                dataset['transmittance'],
                p0=[initial_eps_bg],
                bounds=([bounds_eps_bg[0]], [bounds_eps_bg[1]]),
                maxfev=3000,
                method='trf'
            )
            
            eps_bg_fit = popt[0]
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç‰©ç†çš„ã«å¦¥å½“ã‹ãƒã‚§ãƒƒã‚¯
            if bounds_eps_bg[0] <= eps_bg_fit <= bounds_eps_bg[1]:
                print(f"  âœ… æˆåŠŸ (è©¦è¡Œ {attempt + 1}): eps_bg = {eps_bg_fit:.3f}")
                result = {
                    'eps_bg': eps_bg_fit,
                    'd': d_fixed,
                    'temperature': dataset['temperature']
                }
                success = True
                break
            else:
                print(f"  å¤±æ•— (è©¦è¡Œ {attempt + 1}): eps_bg = {eps_bg_fit:.3f} ã¯ç¯„å›²å¤–")
                
        except RuntimeError as e:
            print(f"  å¤±æ•— (è©¦è¡Œ {attempt + 1}): æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼ - {e}")
        except Exception as e:
            print(f"  å¤±æ•— (è©¦è¡Œ {attempt + 1}): ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ - {e}")
    
    if not success:
        print("  âŒ å…¨ã¦ã®è©¦è¡Œã«å¤±æ•—")
        result = {}
    
    return result

# --- PyMC Op ã‚¯ãƒ©ã‚¹ ---
class TemperatureMagneticModelOp(Op):
    """
    â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaå¯¾å¿œ â–¼â–¼â–¼
    æ¸©åº¦"é"ä¾å­˜ã®2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã‚’æ‰±ã†ãŸã‚ã®PyMC Opã€‚
    å…¥åŠ›ã®gamma_concatã¯ (å…¨æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•° * 7) ã®é•·ã•ã‚’æŒã¤ãŒã€
    ä¸­èº«ã¯ [gamma_min, gamma_other, ...] ã®ç¹°ã‚Šè¿”ã—ã¨ãªã£ã¦ã„ã‚‹ã€‚
    """
    def __init__(self, datasets: List[Dict[str, Any]], temperature_specific_params: Dict[float, Dict[str, float]], model_type: str):
        super().__init__()
        self.datasets = datasets
        self.temperature_specific_params = temperature_specific_params
        self.model_type = model_type
        # self.temp_list = sorted(list(set([d['temperature'] for d in datasets]))) # æ¸©åº¦ä¾å­˜æ€§ãŒãªã„ãŸã‚ä¸è¦
        
        # å…¥åŠ›ã‚¿ã‚¤ãƒ—ã¯å¤‰æ›´ãªã— (a_scale, gamma_concat, g_factor, B4, B6)
        self.itypes = [pt.dscalar, pt.dvector, pt.dscalar, pt.dscalar, pt.dscalar]  
        self.otypes = [pt.dvector]
    
    def perform(self, node, inputs, output_storage):
        a_scale, gamma_concat, g_factor, B4, B6 = inputs
        full_predicted_y = []
        gamma_start_idx = 0
        
        for data in self.datasets:
            # è©²å½“ã™ã‚‹æ¸©åº¦ã®å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            temperature = data['temperature']
            if temperature in self.temperature_specific_params:
                d_fixed = self.temperature_specific_params[temperature]['d']
                eps_bg_fixed = self.temperature_specific_params[temperature]['eps_bg']
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                d_fixed = globals()['d_fixed']
                eps_bg_fixed = eps_bg_init
            
            # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 7å€‹ãšã¤åˆ‡ã‚Šå‡ºã™ãƒ­ã‚¸ãƒƒã‚¯ã¯åŒã˜ã ãŒã€ä¸­èº«ã¯æ¸©åº¦ã«ã‚ˆã‚‰ãšä¸€å®š â–¼â–¼â–¼
            gamma_end_idx = gamma_start_idx + 7
            gamma_for_temp = gamma_concat[gamma_start_idx:gamma_end_idx] 
            gamma_start_idx = gamma_end_idx
            
            # ç‰©ç†ãƒ¢ãƒ‡ãƒ«è¨ˆç®—
            H = get_hamiltonian(B_FIXED, g_factor, B4, B6)
            chi_raw = calculate_susceptibility(data['omega'], H, temperature, gamma_for_temp)
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ã®è¨ˆç®—
            G0 = a_scale * mu0 * N_spin * (g_factor * muB)**2 / (2 * hbar)
            chi = G0 * chi_raw
            
            # ãƒ¢ãƒ‡ãƒ«å½¢å¼ã«å¿œã˜ãŸé€ç£ç‡è¨ˆç®—
            if self.model_type == 'B_form':
                mu_r = 1 / (1 - chi)
            else:  # H_form (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
                mu_r = 1 + chi
            
            # é€éç‡è¨ˆç®—
            predicted_trans = calculate_normalized_transmission(data['omega'], mu_r, d_fixed, eps_bg_fixed)
            
            # æ•°å€¤çš„å®‰å®šæ€§ã®ãƒã‚§ãƒƒã‚¯
            predicted_trans = np.where(np.isfinite(predicted_trans), predicted_trans, 0.5)
            predicted_trans = np.clip(predicted_trans, 0, 1)
            
            full_predicted_y.extend(predicted_trans)
        
        output_storage[0][0] = np.array(full_predicted_y)

# â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaå¯¾å¿œ â–¼â–¼â–¼
def extract_bayesian_parameters(trace: az.InferenceData) -> Dict[str, float]:
    """ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã‹ã‚‰å¹³å‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆ2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaå¯¾å¿œï¼‰"""
    posterior = trace["posterior"]
    a_scale_mean = posterior['a_scale'].mean().item()
    g_factor_mean = posterior['g_factor'].mean().item()
    result = {
        'a_scale': a_scale_mean,
        'g_factor': g_factor_mean,
        'B4': posterior['B4'].mean().item(),
        'B6': posterior['B6'].mean().item(),
        'G0': a_scale_mean * mu0 * N_spin * (g_factor_mean * muB)**2 / (2 * hbar)
    }
    
    # 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã®å€¤ã‚’è¿½åŠ 
    try:
        result['log_gamma_min'] = posterior['log_gamma_min'].mean().item()
        result['log_gamma_other'] = posterior['log_gamma_other'].mean().item()
        # ç‰©ç†çš„ãªgammaå€¤ã‚‚è¨ˆç®—ã—ã¦è¿½åŠ 
        result['gamma_min'] = np.exp(result['log_gamma_min'])
        result['gamma_other'] = np.exp(result['log_gamma_other'])
    except KeyError:
        # gammaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        print("è­¦å‘Š: gamma_min / gamma_other ãŒãƒˆãƒ¬ãƒ¼ã‚¹ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        pass
    
    return result

# --- äº‹å‰åˆ†å¸ƒè¨­å®šé–¢æ•° ---
def create_prior_distributions(prior_config: Dict[str, Any], 
                              prior_magnetic_params: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®äº‹å‰åˆ†å¸ƒã‚’ä½œæˆã™ã‚‹"""
    priors = {}
    
    if prior_magnetic_params is None:
        # åˆå›å®Ÿè¡Œæ™‚ï¼šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã® magnetic_parameters ã‚’ä½¿ç”¨
        mag_config = prior_config['magnetic_parameters']
        
        # a_scale
        if mag_config['a_scale']['distribution'] == 'HalfNormal':
            priors['a_scale'] = pm.HalfNormal('a_scale', sigma=mag_config['a_scale']['sigma'])
        
        # g_factor
        if mag_config['g_factor']['distribution'] == 'Normal':
            priors['g_factor'] = pm.Normal('g_factor', mu=g_factor_init, sigma=mag_config['g_factor']['sigma'])
        
        # B4
        if mag_config['B4']['distribution'] == 'Normal':
            priors['B4'] = pm.Normal('B4', mu=B4_init, sigma=mag_config['B4']['sigma'])
        
        # B6
        if mag_config['B6']['distribution'] == 'Normal':
            priors['B6'] = pm.Normal('B6', mu=B6_init, sigma=mag_config['B6']['sigma'])
            
    else:
        # äº‹å‰æƒ…å ±ãŒã‚ã‚‹å ´åˆï¼šwith_prior_info ã‚’ä½¿ç”¨
        prior_config_info = prior_config['with_prior_info']
        
        # a_scale
        if prior_config_info['a_scale']['distribution'] == 'Normal':
            priors['a_scale'] = pm.Normal('a_scale', mu=prior_magnetic_params['a_scale'], 
                                        sigma=prior_config_info['a_scale']['sigma'])
        
        # g_factor
        if prior_config_info['g_factor']['distribution'] == 'Normal':
            priors['g_factor'] = pm.Normal('g_factor', mu=prior_magnetic_params['g_factor'], 
                                         sigma=prior_config_info['g_factor']['sigma'])
        
        # B4
        if prior_config_info['B4']['distribution'] == 'Normal':
            priors['B4'] = pm.Normal('B4', mu=prior_magnetic_params['B4'], 
                                   sigma=prior_config_info['B4']['sigma'])
        
        # B6
        if prior_config_info['B6']['distribution'] == 'Normal':
            priors['B6'] = pm.Normal('B6', mu=prior_magnetic_params['B6'], 
                                   sigma=prior_config_info['B6']['sigma'])
    
    return priors

# â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã®äº‹å‰åˆ†å¸ƒä½œæˆé–¢æ•° â–¼â–¼â–¼
def create_gamma_priors(gamma_config: Dict[str, Any], gamma_init_val: float) -> Dict[str, Any]:
    """
    gammaé–¢é€£ã®äº‹å‰åˆ†å¸ƒã‚’ä½œæˆã™ã‚‹ (2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»æ¸©åº¦éä¾å­˜ç‰ˆ)
    
    Args:
        gamma_config: configã® 'gamma_parameters' ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        gamma_init_val: åˆæœŸå€¤ (äº‹å‰åˆ†å¸ƒã®å¹³å‡ã¨ã—ã¦ä½¿ç”¨)
    """
    gamma_priors = {}
    log_gamma_init = np.log(gamma_init_val)
    
    # log_gamma_min (æœ€ä½æ¬¡é·ç§»)
    cfg_min = gamma_config.get('log_gamma_min', {'distribution': 'Normal', 'sigma': 1.0})
    if cfg_min['distribution'] == 'Normal':
        gamma_priors['log_gamma_min'] = pm.Normal('log_gamma_min', 
                                                mu=log_gamma_init, 
                                                sigma=cfg_min['sigma'])
    
    # log_gamma_other (ãã®ä»–é«˜æ¬¡é·ç§»)
    cfg_other = gamma_config.get('log_gamma_other', {'distribution': 'Normal', 'sigma': 1.0})
    if cfg_other['distribution'] == 'Normal':
        gamma_priors['log_gamma_other'] = pm.Normal('log_gamma_other', 
                                                  mu=log_gamma_init, 
                                                  sigma=cfg_other['sigma'])
    
    return gamma_priors

# --- é‡ã¿ä»˜ããƒ™ã‚¤ã‚ºæ¨å®šãƒ¡ã‚¤ãƒ³é–¢æ•° ---
def run_temperature_bayesian_fit(datasets: List[Dict[str, Any]], 
                                temperature_specific_params: Dict[float, Dict[str, float]],
                                weights_list: List[np.ndarray], 
                                results_dir: pathlib.Path,
                                prior_magnetic_params: Optional[Dict[str, float]] = None, 
                                model_type: str = 'H_form') -> Optional[az.InferenceData]:
    print(f"\n--- é‡ã¿ä»˜ããƒ™ã‚¤ã‚ºæ¨å®š (ãƒ¢ãƒ‡ãƒ«: {model_type}, Gamma: 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿) ---")
    
    # è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã¨é‡ã¿ã‚’çµåˆ
    combined_weights = np.concatenate(weights_list)

    with pm.Model() as model:
        # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®äº‹å‰åˆ†å¸ƒè¨­å®š â–¼â–¼â–¼
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰äº‹å‰åˆ†å¸ƒè¨­å®šã‚’å–å¾—
        prior_config = CONFIG['bayesian_priors']
        
        # ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®äº‹å‰åˆ†å¸ƒã‚’ä½œæˆ
        magnetic_priors = create_prior_distributions(prior_config, prior_magnetic_params)
        a_scale = magnetic_priors['a_scale']
        g_factor = magnetic_priors['g_factor'] 
        B4 = magnetic_priors['B4']
        B6 = magnetic_priors['B6']
        
        # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã®äº‹å‰åˆ†å¸ƒã‚’ä½œæˆ â–¼â–¼â–¼
        gamma_priors = create_gamma_priors(prior_config['gamma_parameters'], gamma_init)
        log_gamma_min = gamma_priors['log_gamma_min']
        log_gamma_other = gamma_priors['log_gamma_other']
        
        # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ æ¸©åº¦éä¾å­˜ã®gammaé…åˆ—ã‚’æ§‹ç¯‰ â–¼â–¼â–¼
        gamma_min = pt.exp(log_gamma_min)
        gamma_other = pt.exp(log_gamma_other)
        
        # 7è¦ç´ ã®ãƒ™ãƒ¼ã‚¹é…åˆ—ã‚’ä½œæˆ [min, other, other, other, other, other, other]
        # (calculate_susceptibilityã®å®Ÿè£…ä¸Šã€æœ€åˆã®è¦ç´ ãŒ E1-E0 ã«å¯¾å¿œã™ã‚‹ãŸã‚)
        gamma_base_vec = pt.concatenate([
            pt.stack([gamma_min]),         # 1è¦ç´ 
            pt.repeat(gamma_other, 6)      # 6è¦ç´ 
        ])
        
        # å„æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã“ã® 'gamma_base_vec' ã‚’ä½¿ç”¨ã™ã‚‹
        gamma_final = []
        for _ in datasets: # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•°ã ã‘è¤‡è£½
            gamma_final.append(gamma_base_vec)
        
        # Opã«æ¸¡ã™ãŸã‚ã®é•·ã„é…åˆ— (T_count * 7 è¦ç´ )
        gamma_concat = pt.concatenate(gamma_final, axis=0)
        
        # é‡ã¿ä»˜ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ã®Opã‚’ä½¿ç”¨
        # é‡ã¿ãŒ0ã‚ˆã‚Šå¤§ãã„ãƒ‡ãƒ¼ã‚¿ç‚¹ã®ã¿ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã«ä½¿ç”¨ã™ã‚‹
        datasets_weighted = []
        weights_start_idx = 0
        for i, data in enumerate(datasets):
            n_points = len(data['transmittance_full'])
            weights_end_idx = weights_start_idx + n_points
            
            # ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é‡ã¿
            dataset_weights = combined_weights[weights_start_idx:weights_end_idx]
            dataset_valid_indices = np.where(dataset_weights > 0)[0]
            
            if len(dataset_valid_indices) > 0:
                # é‡ã¿ä»˜ã‘ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
                weighted_dataset = {
                    'temperature': data['temperature'],
                    'b_field': data['b_field'],
                    'frequency': data['frequency'][dataset_valid_indices],
                    'transmittance_full': data['transmittance_full'][dataset_valid_indices],
                    'omega': data['omega'][dataset_valid_indices],
                    'weights': dataset_weights[dataset_valid_indices]
                }
                datasets_weighted.append(weighted_dataset)
            
            weights_start_idx = weights_end_idx
        
        if datasets_weighted:
            op_weighted = TemperatureMagneticModelOp(datasets_weighted, temperature_specific_params, model_type)
            mu = op_weighted(a_scale, gamma_concat, g_factor, B4, B6)
            
            # é‡ã¿é…åˆ—ã‚’çµ±åˆ
            weights_tensor = pt.as_tensor_variable(np.concatenate([d['weights'] for d in datasets_weighted]))
            
            # ãƒã‚¤ã‚ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
            noise_config = prior_config['noise_parameters']['sigma']
            if noise_config['distribution'] == 'HalfNormal':
                sigma = pm.HalfNormal('sigma', sigma=noise_config['sigma'])
            else:
                sigma = pm.HalfNormal('sigma', sigma=0.05)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            
            # é‡ã¿ã«å¿œã˜ã¦sigmaã‚’èª¿æ•´ (é‡ã¿ãŒå¤§ãã„ã»ã©sigmaã¯å°ã•ããªã‚‹)
            sigma_adjusted = sigma / pt.sqrt(weights_tensor)
            
            # é‡ã¿ä»˜ããƒ‡ãƒ¼ã‚¿ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            trans_target = np.concatenate([d['transmittance_full'] for d in datasets_weighted])
            
            # é‡ã¿ä»˜ã‘ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§å°¤åº¦ã‚’è¨ˆç®—
            Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma_adjusted, observed=trans_target)
        else:
            print("âš ï¸ è­¦å‘Š: æœ‰åŠ¹ãªé‡ã¿ä»˜ããƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®šï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
        try:
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™
            sample_kwargs = {
                'draws': MCMC_CONFIG['draws'], 
                'tune': MCMC_CONFIG['tune'], 
                'chains': MCMC_CONFIG['chains'],
                'target_accept': MCMC_CONFIG['target_accept'],
                'random_seed': MCMC_CONFIG.get('random_seed', None),  # å†ç¾æ€§ç¢ºä¿
                'init': MCMC_CONFIG.get('init', 'auto'),
                'return_inferencedata': True,
                'progressbar': True,
                'idata_kwargs': {'log_likelihood': True}  # LOO-CVç”¨ã«log_likelihoodã‚’ä¿å­˜
            }
            
            # â–¼â–¼â–¼ NUTSã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã®æŒ‡å®šï¼ˆconfig.ymlã«åŸºã¥ãï¼‰ â–¼â–¼â–¼
            if 'nuts_sampler' in MCMC_CONFIG:
                sample_kwargs['nuts_sampler'] = MCMC_CONFIG['nuts_sampler']
                print(f"ğŸš€ NUTS Sampler: {sample_kwargs['nuts_sampler']} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            else:
                print("ğŸš€ NUTS Sampler: PyMC default ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

            trace = pm.sample(**sample_kwargs)
            print("âœ… ãƒ™ã‚¤ã‚ºã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚")
            
            # åæŸè¨ºæ–­ã®è‡ªå‹•ãƒã‚§ãƒƒã‚¯
            print("\n--- åæŸè¨ºæ–­ ---")
            # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ è¨ºæ–­å¯¾è±¡ã«gammaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ  â–¼â–¼â–¼
            diagnostic_vars = ['a_scale', 'g_factor', 'B4', 'B6', 'log_gamma_min', 'log_gamma_other']
            convergence_issues = []
            
            for var in diagnostic_vars:
                try:
                    var_summary = az.summary(trace, var_names=[var])
                    r_hat = var_summary['r_hat'].values[0]
                    ess_bulk = var_summary['ess_bulk'].values[0]
                    
                    # r_hatè¨ºæ–­
                    if r_hat > 1.05:
                        convergence_issues.append(f"âš ï¸ {var}: r_hat={r_hat:.3f} (ç›®æ¨™<1.05)")
                    elif r_hat > 1.01:
                        print(f"âš¡ {var}: r_hat={r_hat:.3f} (è¨±å®¹ç¯„å›²å†…ã ãŒæ³¨æ„)")
                    else:
                        print(f"âœ… {var}: r_hat={r_hat:.3f} (è‰¯å¥½)")
                    
                    # ESSè¨ºæ–­
                    if ess_bulk < 400:
                        convergence_issues.append(f"âš ï¸ {var}: ess_bulk={ess_bulk:.0f} (ç›®æ¨™>400)")
                    else:
                        print(f"âœ… {var}: ess_bulk={ess_bulk:.0f} (ååˆ†)")
                        
                except Exception as e:
                    print(f"  {var}ã®è¨ºæ–­ã«å¤±æ•—: {e}")
            
            if convergence_issues:
                print("\nğŸ”´ åæŸã«å•é¡ŒãŒã‚ã‚Šã¾ã™:")
                for issue in convergence_issues:
                    print(f"  {issue}")
                print("  æ¨å¥¨: draws/tuneã‚’å¢—ã‚„ã™ã‹ã€ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡ç´ åŒ–ã—ã¦ãã ã•ã„ã€‚")
            else:
                print("\nâœ… å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒåæŸåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚")
                
        except Exception as e:
            print(f"âŒ ãƒ™ã‚¤ã‚ºã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None

    # ãƒ™ã‚¤ã‚ºæ¨å®šçµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    trace_filename = results_dir / f'trace_{model_type}.nc'
    az.to_netcdf(trace, trace_filename)
    print(f"âœ… Traceã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {trace_filename}")

    print("----------------------------------------------------")
    print("â–¶ æ¸©åº¦ä¾å­˜ãƒ™ã‚¤ã‚ºæ¨å®šçµæœ (ã‚µãƒãƒªãƒ¼):")
    try:
        # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ gammaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒªãƒ¼ã«è¿½åŠ  â–¼â–¼â–¼
        summary_vars = ['a_scale', 'g_factor', 'B4', 'B6', 'log_gamma_min', 'log_gamma_other', 'sigma']
        summary = az.summary(trace, var_names=summary_vars)
        print(summary)
    except KeyError as e:
        print(f"ã‚µãƒãƒªãƒ¼è¡¨ç¤ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        try:
            summary = az.summary(trace)
            print(summary)
        except:
            print("ã‚µãƒãƒªãƒ¼ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    print("----------------------------------------------------")
    return trace

# â–¼â–¼â–¼ äº‹å¾Œåˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆé–¢æ•°ã®è¿½åŠ  â–¼â–¼â–¼
# â–¼â–¼â–¼ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaå¯¾å¿œ â–¼â–¼â–¼
def plot_posterior_distributions(trace: az.InferenceData, model_type: str, results_dir: pathlib.Path):
    """
    ãƒ™ã‚¤ã‚ºæ¨å®šã®äº‹å¾Œåˆ†å¸ƒã¨ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã‚’å¯è¦–åŒ–ã—ã€ä¿å­˜ã™ã‚‹ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®åæŸã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ†å¸ƒå½¢çŠ¶ã‚’ç¢ºèªã§ãã‚‹ã€‚
    """
    print(f"\n--- {model_type}ãƒ¢ãƒ‡ãƒ«ã®äº‹å¾Œåˆ†å¸ƒã‚’ãƒ—ãƒ­ãƒƒãƒˆä¸­ ---")
    
    # ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ä¸»è¦ãªå¤‰æ•°ã‚’æŒ‡å®š (2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaå¯¾å¿œ)
    var_names = ['a_scale', 'g_factor', 'B4', 'B6', 
                 'log_gamma_min', 'log_gamma_other'] 
    
    try:
        # ArviZã®plot_traceã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ
        axes = az.plot_trace(trace, var_names=var_names, compact=True, kind='rank_bars')
        plt.suptitle(f'Posterior Trace Plot for {model_type} Model', fontsize=16, y=1.02)
        fig = plt.gcf() # ç¾åœ¨ã®Figureã‚’å–å¾—
        fig.tight_layout(rect=(0, 0, 1, 0.98), h_pad=3.0, w_pad=2.0)
        fig.savefig(results_dir / f'posterior_trace_{model_type}.png', bbox_inches='tight')
        print(f"âœ… äº‹å¾Œåˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: posterior_trace_{model_type}.png")

    except Exception as e:
        print(f"âš ï¸ äº‹å¾Œåˆ†å¸ƒã®ãƒ—ãƒ­ãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --- çµæœä¿å­˜ãƒ»å¯è¦–åŒ–é–¢æ•°ç¾¤ ---
def fit_single_temperature_cavity_modes(dataset: Dict[str, Any], 
                                      bayesian_params: Optional[Dict[str, float]] = None) -> Dict[str, float]:
    """é«˜å‘¨æ³¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰eps_bgãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆãƒ™ã‚¤ã‚ºæ¨å®šçµæœå¯¾å¿œç‰ˆï¼‰"""
    return fit_eps_bg_only_temperature(dataset, bayesian_params=bayesian_params)

def save_fitting_parameters_to_csv(final_traces: Dict[str, az.InferenceData], 
                                  model_temperature_params: Dict[str, Dict[float, Dict[str, float]]],
                                  results_dir: pathlib.Path):
    """ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆä¸¡ãƒ¢ãƒ‡ãƒ«å¯¾å¿œç‰ˆï¼‰"""
    print("\n--- ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã‚’CSVã«ä¿å­˜ä¸­ ---")
    
    # ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµæœã‚’ä¿å­˜
    for model_type, trace in final_traces.items():
        # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaå¯¾å¿œã®é–¢æ•°ã‚’å‘¼ã¶ â–¼â–¼â–¼
        params = extract_bayesian_parameters(trace)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµæœ
        params_df = pd.DataFrame([params])
        params_file = results_dir / f'fitting_parameters_{model_type}.csv'
        params_df.to_csv(params_file, index=False)
        print(f"âœ… ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜: {params_file}")
    
    # å„ãƒ¢ãƒ‡ãƒ«ã®æ¸©åº¦åˆ¥å…‰å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜
    for model_type, temperature_specific_params in model_temperature_params.items():
        temp_params_list = []
        for temp, params in sorted(temperature_specific_params.items()):
            temp_params_list.append(params)
        
        if temp_params_list:
            temp_df = pd.DataFrame(temp_params_list)
            temp_file = results_dir / f'temperature_optical_parameters_{model_type}.csv'
            temp_df.to_csv(temp_file, index=False)
            print(f"âœ… {model_type}ã®æ¸©åº¦åˆ¥å…‰å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜: {temp_file}")

def plot_temperature_dependencies(model_temperature_params: Dict[str, Dict[float, Dict[str, float]]], 
                                final_traces: Dict[str, az.InferenceData],
                                results_dir: pathlib.Path):
    """æ¸©åº¦ä¾å­˜æ€§ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ï¼ˆä¸¡ãƒ¢ãƒ‡ãƒ«å¯¾å¿œç‰ˆï¼‰"""
    print("\n--- æ¸©åº¦ä¾å­˜æ€§ã®å¯è¦–åŒ–ï¼ˆä¸¡ãƒ¢ãƒ‡ãƒ«ï¼‰ ---")
    
    # å…¨ãƒ¢ãƒ‡ãƒ«ã§å…±é€šã®æ¸©åº¦ãƒªã‚¹ãƒˆã‚’å–å¾—
    all_temps = set()
    for model_params in model_temperature_params.values():
        all_temps.update(model_params.keys())
    temperatures = sorted(all_temps)
    
    # å„ãƒ¢ãƒ‡ãƒ«ã®eps_bgå€¤ã‚’åé›†
    model_eps_bg = {}
    for model_type, temp_params in model_temperature_params.items():
        model_eps_bg[model_type] = [temp_params[T]['eps_bg'] for T in temperatures if T in temp_params]
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: ä¸¡ãƒ¢ãƒ‡ãƒ«ã®eps_bgæ¯”è¼ƒ
    ax1 = axes[0, 0]
    colors = {'H_form': 'red', 'B_form': 'blue'}
    markers = {'H_form': 'o', 'B_form': 's'}
    
    for model_type, eps_values in model_eps_bg.items():
        temps_for_model = [T for T in temperatures if T in model_temperature_params[model_type]]
        ax1.plot(temps_for_model, eps_values, 
                color=colors.get(model_type, 'gray'), 
                marker=markers.get(model_type, 'o'),
                linewidth=2, markersize=8, 
                label=f'{model_type}')
    
    ax1.set_xlabel('æ¸©åº¦ (K)', fontsize=12)
    ax1.set_ylabel('èƒŒæ™¯èª˜é›»ç‡ eps_bg', fontsize=12)
    ax1.set_title('èƒŒæ™¯èª˜é›»ç‡ã®æ¸©åº¦ä¾å­˜æ€§ï¼ˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼‰', fontsize=14)
    ax1.grid(True, linestyle='--', alpha=0.6)
    ax1.legend(fontsize=11)
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: eps_bgã®å·®åˆ†
    ax2 = axes[0, 1]
    if 'H_form' in model_eps_bg and 'B_form' in model_eps_bg:
        common_temps = [T for T in temperatures 
                       if T in model_temperature_params['H_form'] 
                       and T in model_temperature_params['B_form']]
        h_form_eps = [model_temperature_params['H_form'][T]['eps_bg'] for T in common_temps]
        b_form_eps = [model_temperature_params['B_form'][T]['eps_bg'] for T in common_temps]
        eps_diff = [h - b for h, b in zip(h_form_eps, b_form_eps)]
        
        ax2.plot(common_temps, eps_diff, 'go-', linewidth=2, markersize=8)
        ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        ax2.set_xlabel('æ¸©åº¦ (K)', fontsize=12)
        ax2.set_ylabel('Î”eps_bg (H_form - B_form)', fontsize=12)
        ax2.set_title('ä¸¡ãƒ¢ãƒ‡ãƒ«é–“ã®eps_bgå·®åˆ†', fontsize=14)
        ax2.grid(True, linestyle='--', alpha=0.6)
    else:
        ax2.text(0.5, 0.5, 'ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãªã—', 
                ha='center', va='center', transform=ax2.transAxes, fontsize=14)
        ax2.axis('off')
    
    # â–¼â–¼â–¼ã€å¤‰æ›´ã€‘ 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿gammaã®çµæœã‚’è¡¨ç¤º â–¼â–¼â–¼
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ3: H_formã®ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼
    ax3 = axes[1, 0]
    if 'H_form' in final_traces:
        h_params = extract_bayesian_parameters(final_traces['H_form'])
        ax3.text(0.1, 0.95, 'H_formãƒ¢ãƒ‡ãƒ« ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:', fontsize=14, transform=ax3.transAxes, weight='bold')
        ax3.text(0.1, 0.80, f'gå› å­ = {h_params["g_factor"]:.6f}', fontsize=12, transform=ax3.transAxes)
        ax3.text(0.1, 0.70, f'B4 = {h_params["B4"]:.6f} K', fontsize=12, transform=ax3.transAxes)
        ax3.text(0.1, 0.60, f'B6 = {h_params["B6"]:.6f} K', fontsize=12, transform=ax3.transAxes)
        ax3.text(0.1, 0.50, f'a_scale = {h_params["a_scale"]:.6f}', fontsize=12, transform=ax3.transAxes)
        ax3.text(0.1, 0.40, f'G0 = {h_params["G0"]:.3e}', fontsize=12, transform=ax3.transAxes)
        if 'gamma_min' in h_params:
            ax3.text(0.1, 0.25, f'gamma_min = {h_params["gamma_min"]:.3e}', fontsize=12, transform=ax3.transAxes)
            ax3.text(0.1, 0.15, f'gamma_other = {h_params["gamma_other"]:.3e}', fontsize=12, transform=ax3.transAxes)
    ax3.set_xlim(0, 1)
    ax3.set_ylim(0, 1)
    ax3.set_title('H_formè§£æçµæœ', fontsize=14)
    ax3.axis('off')
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ4: B_formã®ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼
    ax4 = axes[1, 1]
    if 'B_form' in final_traces:
        b_params = extract_bayesian_parameters(final_traces['B_form'])
        ax4.text(0.1, 0.95, 'B_formãƒ¢ãƒ‡ãƒ« ç£æ°—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:', fontsize=14, transform=ax4.transAxes, weight='bold')
        ax4.text(0.1, 0.80, f'gå› å­ = {b_params["g_factor"]:.6f}', fontsize=12, transform=ax4.transAxes)
        ax4.text(0.1, 0.70, f'B4 = {b_params["B4"]:.6f} K', fontsize=12, transform=ax4.transAxes)
        ax4.text(0.1, 0.60, f'B6 = {b_params["B6"]:.6f} K', fontsize=12, transform=ax4.transAxes)
        ax4.text(0.1, 0.50, f'a_scale = {b_params["a_scale"]:.6f}', fontsize=12, transform=ax4.transAxes)
        ax4.text(0.1, 0.40, f'G0 = {b_params["G0"]:.3e}', fontsize=12, transform=ax4.transAxes)
        if 'gamma_min' in b_params:
            ax4.text(0.1, 0.25, f'gamma_min = {b_params["gamma_min"]:.3e}', fontsize=12, transform=ax4.transAxes)
            ax4.text(0.1, 0.15, f'gamma_other = {b_params["gamma_other"]:.3e}', fontsize=12, transform=ax4.transAxes)
    ax4.set_xlim(0, 1)
    ax4.set_ylim(0, 1)
    ax4.set_title('B_formè§£æçµæœ', fontsize=14)
    ax4.axis('off')
    
    plt.tight_layout()
    plt.savefig(results_dir / 'temperature_dependencies_comparison.png', dpi=300, bbox_inches='tight')
    print(f"âœ… æ¸©åº¦ä¾å­˜æ€§æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜: temperature_dependencies_comparison.png")

# --- ãƒ€ãƒŸãƒ¼é–¢æ•°ï¼ˆå°†æ¥çš„ãªæ©Ÿèƒ½æ‹¡å¼µç”¨ï¼‰---
def plot_combined_temperature_model_comparison(*args, **kwargs):
    print("âš ï¸ plot_combined_temperature_model_comparison ã¯æœªå®Ÿè£…ã§ã™ã€‚")

def plot_model_selection_results_temperature(*args, **kwargs):
    print("âš ï¸ plot_model_selection_results_temperature ã¯æœªå®Ÿè£…ã§ã™ã€‚")

def calculate_temperature_peak_errors(*args, **kwargs):
    print("âš ï¸ calculate_temperature_peak_errors ã¯æœªå®Ÿè£…ã§ã™ã€‚")
    return {}

def save_peak_analysis_to_csv(*args, **kwargs):
    print("âš ï¸ save_peak_analysis_to_csv ã¯æœªå®Ÿè£…ã§ã™ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–¢æ•° ---
def run_analysis_workflow():
    """
    é‡ã¿ä»˜ã‘ã‚’åˆ©ç”¨ã—ãŸæ¸©åº¦ä¾å­˜ãƒ™ã‚¤ã‚ºæ¨å®šãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€‚
    1. ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€é«˜å‘¨æ³¢ã¨å…¨å‘¨æ³¢æ•°é ˜åŸŸã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã€‚
    2. é«˜å‘¨æ³¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å„æ¸©åº¦ã®eps_bgã‚’ä¸€åº¦ã ã‘ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã€‚
    3. å…¨å‘¨æ³¢æ•°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ”ãƒ¼ã‚¯æƒ…å ±ã‚’åŸºã«å‘¨æ³¢æ•°ã”ã¨ã®é‡ã¿é…åˆ—ã‚’ç”Ÿæˆã€‚
    4. é‡ã¿ä»˜ã‘ã—ãŸå°¤åº¦é–¢æ•°ã‚’ç”¨ã„ã¦ãƒ™ã‚¤ã‚ºæ¨å®šã‚’å®Ÿè¡Œã€‚
    5. çµæœã‚’å¯è¦–åŒ–ãƒ»ä¿å­˜ã™ã‚‹ã€‚
    """
    # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ã®ã¿å®Ÿè¡Œï¼‰
    results_dir = create_results_directory(CONFIG)
    print(f"ç”»åƒã¯ '{results_dir.resolve()}' ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚")
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚‚æ›´æ–°ï¼ˆä»–ã®éƒ¨åˆ†ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ãŸã‚ï¼‰
    global RESULTS_DIR
    RESULTS_DIR = results_dir
    
    print("ğŸš€ é‡ã¿ä»˜ããƒ™ã‚¤ã‚ºæ¨å®šãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™ (Gamma: 2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç‰ˆ)")
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print("\n--- ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆ†å‰² ---")
    all_data = load_and_split_data_three_regions_temperature(
        file_path=DATA_FILE_PATH,
        sheet_name=DATA_SHEET_NAME
    )
    all_datasets_full_range = all_data['all_full']
    high_freq_datasets = all_data['high_freq']

    if not all_datasets_full_range or not high_freq_datasets:
        print("âŒ å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return
        
    # 2. åˆå›ã®eps_bgãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆåˆæœŸå€¤ä½¿ç”¨ï¼‰
    print("\n--- ã‚¹ãƒ†ãƒƒãƒ—2: åˆå›eps_bgãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆåˆæœŸå€¤ä½¿ç”¨ï¼‰ ---")
    temperature_specific_params = {}
    for dataset in high_freq_datasets:
        temp = dataset['temperature']
        result = fit_eps_bg_only_temperature(dataset, bayesian_params=None)  # åˆå›ã¯åˆæœŸå€¤
        if result:
            temperature_specific_params[temp] = result
        else:
            temperature_specific_params[temp] = {'eps_bg': eps_bg_init, 'd': d_fixed, 'temperature': temp}

    # 3. å‘¨æ³¢æ•°ã”ã¨ã®é‡ã¿é…åˆ—ã‚’ç”Ÿæˆ
    print("\n--- ã‚¹ãƒ†ãƒƒãƒ—3: å°¤åº¦é–¢æ•°ã®ãŸã‚ã®é‡ã¿é…åˆ—ã‚’ç”Ÿæˆ ---")
    analysis_settings = CONFIG['analysis_settings']
    weights_list = [create_frequency_weights(d, analysis_settings) for d in all_datasets_full_range]
    
    # 4. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ãƒ«ãƒ¼ãƒ—ï¼ˆãƒ™ã‚¤ã‚ºæ¨å®š â†’ eps_bgæ›´æ–°ï¼‰
    # å„ãƒ¢ãƒ‡ãƒ«ãŒç‹¬ç«‹ã—ãŸeps_bgãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤
    final_traces = {}
    model_temperature_params = {
        'H_form': temperature_specific_params.copy(),  # H_formç”¨ã®eps_bg
        'B_form': temperature_specific_params.copy()   # B_formç”¨ã®eps_bg
    }
    max_iterations = CONFIG['mcmc'].get('max_iterations', 3)  # æ›´æ–°å›æ•°ã®åˆ¶é™ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3å›)
    
    for iteration in range(max_iterations):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ åå¾© {iteration + 1}/{max_iterations}: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ãƒ«ãƒ¼ãƒ—")
        print(f"{'='*60}")
        
        # 4-1. å„ãƒ¢ãƒ‡ãƒ«ã§ç‹¬ç«‹ã«ãƒ™ã‚¤ã‚ºæ¨å®š â†’ eps_bgæ›´æ–°ã‚’å®Ÿè¡Œ
        for model_type in ['H_form', 'B_form']:
            print(f"\n{'='*50}")
            print(f"ğŸ”¬ {model_type}ãƒ¢ãƒ‡ãƒ«ã®ç‹¬ç«‹å‡¦ç†")
            print(f"{'='*50}")
            
            # 4-1-1. ãƒ™ã‚¤ã‚ºæ¨å®š
            print(f"\n--- ã‚¹ãƒ†ãƒƒãƒ—4-{iteration+1}-1: {model_type}ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ã‚¤ã‚ºæ¨å®š ---")
            
            # å„ãƒ¢ãƒ‡ãƒ«ã¯è‡ªåˆ†è‡ªèº«ã®å‰å›ã®çµæœã®ã¿ã‚’äº‹å‰åˆ†å¸ƒã¨ã—ã¦ä½¿ç”¨ï¼ˆå…¬å¹³ãªæ¯”è¼ƒã®ãŸã‚ï¼‰
            model_specific_prior = None
            if iteration > 0 and model_type in final_traces:
                # 2å›ç›®ä»¥é™ã®åå¾©ã§ã¯ã€å‰å›ã®è‡ªåˆ†è‡ªèº«ã®çµæœã‚’ä½¿ç”¨
                model_specific_prior = extract_bayesian_parameters(final_traces[model_type])
                print(f"  ğŸ“Œ å‰å›ã®{model_type}ã®çµæœã‚’äº‹å‰åˆ†å¸ƒã¨ã—ã¦ä½¿ç”¨:")
                print(f"     a_scale = {model_specific_prior['a_scale']:.6f}")
                print(f"     g_factor = {model_specific_prior['g_factor']:.6f}")
                print(f"     B4 = {model_specific_prior['B4']:.6f}")
                print(f"     B6 = {model_specific_prior['B6']:.6f}")
            else:
                print(f"  ğŸ”° åˆå›å®Ÿè¡Œã®ãŸã‚ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸå€¤ã‚’äº‹å‰åˆ†å¸ƒã¨ã—ã¦ä½¿ç”¨")
            
            # ã“ã®ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®eps_bgãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            trace = run_temperature_bayesian_fit(
                all_datasets_full_range,
                model_temperature_params[model_type],  # ãƒ¢ãƒ‡ãƒ«ç‹¬ç«‹ã®eps_bg
                weights_list,
                results_dir,  # å¼•æ•°ã¨ã—ã¦æ¸¡ã™
                prior_magnetic_params=model_specific_prior,  # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ç‹¬ç«‹ã—ãŸäº‹å‰åˆ†å¸ƒ
                model_type=model_type
            )
            
            if trace:
                final_traces[model_type] = trace  # æœ€æ–°çµæœã‚’ä¿å­˜
                
                # äº‹å¾Œåˆ†å¸ƒã‚’ãƒ—ãƒ­ãƒƒãƒˆ
                plot_posterior_distributions(trace, f"{model_type}_iter{iteration+1}", results_dir)
                
                # 4-1-2. ã“ã®ãƒ¢ãƒ‡ãƒ«ã®çµæœã§eps_bgã‚’æ›´æ–°ï¼ˆæœ€å¾Œã®åå¾©ã§ãªã„å ´åˆï¼‰
                if iteration < max_iterations - 1:
                    print(f"\n--- ã‚¹ãƒ†ãƒƒãƒ—4-{iteration+1}-2: {model_type}ã®eps_bgæ›´æ–° ---")
                    bayesian_params = extract_bayesian_parameters(trace)
                    print(f"  ğŸ”„ {model_type}ãƒ¢ãƒ‡ãƒ«ã®çµæœã§eps_bgãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°:")
                    print(f"     a_scale: {bayesian_params['a_scale']:.6f}")
                    print(f"     g_factor: {bayesian_params['g_factor']:.6f}")
                    print(f"     B4: {bayesian_params['B4']:.6f}")
                    print(f"     B6: {bayesian_params['B6']:.6f}")
                    if 'gamma_min' in bayesian_params:
                         print(f"     gamma_min: {bayesian_params['gamma_min']:.3e}")
                         print(f"     gamma_other: {bayesian_params['gamma_other']:.3e}")
                    
                    # å„æ¸©åº¦ã§eps_bgã‚’å†ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆæ›´æ–°ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
                    updated_temperature_params = {}
                    for dataset in high_freq_datasets:
                        temp = dataset['temperature']
                        result = fit_eps_bg_only_temperature(
                            dataset, 
                            bayesian_params=bayesian_params  # æ›´æ–°ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                        )
                        if result:
                            updated_temperature_params[temp] = result
                        else:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå‰å›ã®çµæœã‚’ä½¿ç”¨
                            updated_temperature_params[temp] = model_temperature_params[model_type].get(
                                temp, {'eps_bg': eps_bg_init, 'd': d_fixed, 'temperature': temp}
                            )
                    
                    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰åŒ–ã‚’ãƒ¬ãƒãƒ¼ãƒˆ
                    print(f"\n  ğŸ“Š {model_type}ã®eps_bgãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰åŒ–ï¼ˆåå¾© {iteration + 1} â†’ {iteration + 2}ï¼‰:")
                    for temp in sorted(model_temperature_params[model_type].keys()):
                        old_eps = model_temperature_params[model_type][temp]['eps_bg']
                        new_eps = updated_temperature_params[temp]['eps_bg']
                        change = new_eps - old_eps
                        print(f"     æ¸©åº¦ {temp}K: {old_eps:.3f} â†’ {new_eps:.3f} (å¤‰åŒ–: {change:+.3f})")
                    
                    # ã“ã®ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®eps_bgã‚’æ›´æ–°
                    model_temperature_params[model_type] = updated_temperature_params
            else:
                print(f"  âŒ {model_type}ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ã‚¤ã‚ºæ¨å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # 5. æœ€çµ‚çµæœã®è©•ä¾¡ã¨å¯è¦–åŒ–
    if not final_traces:
        print("âŒ ãƒ™ã‚¤ã‚ºæ¨å®šãŒå¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return
        
    print(f"\n{'='*60}")
    print("ğŸ¯ æœ€çµ‚çµæœã®è©•ä¾¡ã¨å¯è¦–åŒ–")
    print(f"{'='*60}")
    
    # å„ãƒ¢ãƒ‡ãƒ«ã®eps_bgãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\nğŸ“Š å„ãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚eps_bgãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    for model_type in ['H_form', 'B_form']:
        if model_type in model_temperature_params:
            print(f"\n  {model_type}:")
            for temp in sorted(model_temperature_params[model_type].keys()):
                eps_bg = model_temperature_params[model_type][temp]['eps_bg']
                print(f"    æ¸©åº¦ {temp}K: eps_bg = {eps_bg:.3f}")
    
    # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã®ãŸã‚ã«ã€H_formã®eps_bgã‚’ä½¿ç”¨ï¼ˆãƒ€ãƒŸãƒ¼é–¢æ•°ç”¨ï¼‰
    # Note: å„ãƒ¢ãƒ‡ãƒ«ã¯ç‹¬ç«‹ã—ãŸeps_bgã‚’æŒã¤
    temperature_specific_params = model_temperature_params.get('H_form', {})
    
    if len(final_traces) >= 2:
        plot_combined_temperature_model_comparison(all_datasets_full_range, temperature_specific_params, final_traces)
        plot_model_selection_results_temperature(final_traces)
        peak_analysis_results = calculate_temperature_peak_errors(all_datasets_full_range, temperature_specific_params, final_traces)
        save_peak_analysis_to_csv(peak_analysis_results)
    
    # ä¸¡ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜ãƒ»å¯è¦–åŒ–
    save_fitting_parameters_to_csv(final_traces, model_temperature_params, results_dir)
    plot_temperature_dependencies(model_temperature_params, final_traces, results_dir)

    print("\nğŸ‰ å…¨ã¦ã®è§£æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    print(f"ğŸ“ çµæœã¯ '{results_dir}' ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ ---
if __name__ == "__main__":
    # Windowsç’°å¢ƒã§ã®ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹å•é¡Œå¯¾ç­–
    import multiprocessing
    try:
        multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        # ã™ã§ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
        pass
    
    # è§£æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
    run_analysis_workflow()
