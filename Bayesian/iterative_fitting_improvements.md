# 反復的フィッティング改善点と実行ガイド

## 実装された主な改善点

### 1. 収束条件の強化
- **反復回数**: 5回 → 10回に増加
- **収束判定**: 最大誤差に加えて平均誤差も考慮
  - 最大ピーク誤差 < 1.2%
  - 平均ピーク誤差 < 0.96% (1.2% × 0.8)

### 2. ベイズサンプリングの精度向上
- **サンプル数**: 3,000 → 4,000に増加
- **チューニング**: 4,000 → 5,000に増加
- **チェーン数**: 2 → 4に増加（収束診断の信頼性向上）
- **受容率**: 0.85 → 0.90（より厳密な探索）
- **最大木の深さ**: 10 → 12（より詳細な探索）

### 3. 収束診断基準の厳格化
- **有効サンプルサイズ**: 300 → 400以上を要求
- **r_hat**: 1.01未満を維持（より厳密）

## 実行方法

### 1. 環境の確認
```cmd
conda activate pymc_clean
```

### 2. 実行
```cmd
cd "c:\Users\taich\OneDrive - YNU(ynu.jp)\master\磁性\GGG\Programs\Bayesian"
python two_step_iterative_fitting.py
```

## 期待される改善効果

### 1. 収束性の向上
- より多くの反復によりピーク位置精度の改善
- 磁場7.7Tの一貫した高誤差（1.94%）の解消

### 2. 統計的信頼性の向上
- より多くのサンプルとチェーンによる安定した推定
- 信用区間の精度向上

### 3. パラメータ推定の精度向上
- より厳密なサンプリング設定による高精度推定
- モデル比較の信頼性向上

## 実行時間の予測

改善により実行時間は増加しますが、精度が大幅に向上します：

- **従来版**: 約45-60分
- **改善版**: 約90-120分（2倍程度）

## トラブルシューティング

### 1. 環境エラーが発生する場合
```cmd
# 環境を再作成
conda deactivate
conda env remove -n pymc_clean
conda create -n pymc_clean python=3.11
conda activate pymc_clean
conda install pymc arviz matplotlib pandas numpy scipy openpyxl
```

### 2. メモリエラーが発生する場合
以下のパラメータを調整：
- `draws=3000` に減少
- `chains=2` に減少
- `cores=2` に制限

### 3. 収束しない場合
- `max_iterations=15` に増加
- `peak_error_threshold=0.015` に緩和

## 結果の評価基準

### 成功の指標
1. **全磁場でピーク誤差 < 1.2%**
2. **r_hat < 1.01** （すべてのパラメータ）
3. **ess_bulk, ess_tail > 400**
4. **モデル比較でH_formが優位**

### 結果の確認
1. `iterative_fitting_results.png` - 全体的なフィット品質
2. `eps_bg_and_peak_errors.png` - 磁場依存性とピーク誤差
3. `combined_model_comparison.png` - H_form vs B_form比較
4. `model_comparison_results.csv` - 定量的比較結果

## 注意事項

1. **実行環境**: `pymc_clean`環境必須
2. **実行時間**: 長時間実行のため、PC負荷に注意
3. **メモリ**: 8GB以上推奨
4. **結果保存**: 自動的に`iterative_analysis_results_1`フォルダに保存

## 最終的な目標

- **磁場5.0T**: ピーク誤差 < 1.2%
- **磁場7.7T**: ピーク誤差 < 1.2% （従来1.94%から改善）
- **磁場9.0T**: ピーク誤差 < 1.2%
- **全体平均**: ピーク誤差 < 1.0%
