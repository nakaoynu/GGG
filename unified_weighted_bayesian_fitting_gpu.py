# unified_weighted_bayesian_fitting_gpu.py
# GPU/JAXå¯¾å¿œç‰ˆ: ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã‚’PyTensoråŒ–ã—ã€NumPyroã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’ä½¿ç”¨å¯èƒ½ã«ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³

import time
_import_start = time.time()

import os
import pathlib
import yaml
import sys

# GPUè¨­å®šã®å…ˆè¡Œèª­ã¿è¾¼ã¿
def pre_load_gpu_config():
    try:
        # åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ config_unified_gpu.yml ã‚’æ¢ã™
        config_path = pathlib.Path(__file__).parent / "config_unified_gpu.yml"
        if not config_path.exists():
            return
            
        with open(config_path, 'r', encoding='utf-8') as f:
            temp_config = yaml.safe_load(f)
            
        if temp_config.get('execution', {}).get('use_gpu', False):
            print("ğŸš€ GPU (JAX) ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™...")
            # JAXã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€PyTensorå´ã®deviceæŒ‡å®šã¯ä¸è¦(ã‚€ã—ã‚ã‚¨ãƒ©ãƒ¼ã®å…ƒ)ãªã®ã§floatXã®ã¿æŒ‡å®š
            os.environ['PYTENSOR_FLAGS'] = 'floatX=float64'
        else:
            print("ğŸ’» CPU ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™...")
            os.environ['PYTENSOR_FLAGS'] = 'device=cpu,floatX=float64'
    except Exception as e:
        print(f"âš ï¸ è¨­å®šèª­ã¿è¾¼ã¿è­¦å‘Š: {e}")

pre_load_gpu_config()

import datetime
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pymc as pm
import arviz as az
import pytensor.tensor as pt
import pytensor
from scipy.signal import find_peaks, peak_widths
from scipy.optimize import curve_fit

# æ•°å€¤è¨ˆç®—ã®è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore', category=RuntimeWarning)
warnings.filterwarnings('ignore', category=UserWarning) # PyTensorã®è­¦å‘Šã‚‚ä¸€éƒ¨æŠ‘åˆ¶

# =========================================================
# 1. å…±é€šå®šæ•°ãƒ»è¨­å®šèª­ã¿è¾¼ã¿é–¢æ•°
# =========================================================
kB = 1.380649e-23
muB = 9.274010e-24
hbar = 1.054571e-34
c = 299792458
mu0 = 4.0 * np.pi * 1e-7
s = 3.5

def load_config(config_path=None):
    if config_path is None:
        config_path = pathlib.Path(__file__).parent / "config_unified_gpu.yml"
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def create_results_directory(config):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    parent_dir = config['file_paths'].get('results_parent_dir', 'analysis_results_gpu')
    results_dir = pathlib.Path(__file__).parent / parent_dir / f"run_{timestamp}"
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # configã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    with open(results_dir / "config_used_gpu.yml", 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
    return results_dir

# =========================================================
# 2. NumPyç‰ˆ ç‰©ç†é–¢æ•° (Step 1: eps_bg æœ€é©åŒ–ç”¨)
# =========================================================
# ä»¥å‰ã®ã‚³ãƒ¼ãƒ‰ã®é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆåç§°å¤‰æ›´ãªã—ï¼‰

class HamiltonianCache:
    def __init__(self): self._cache = {}
    def get(self, B, g, B4, B6):
        key = (round(B, 6), round(g, 6), round(B4, 8), round(B6, 8))
        if key not in self._cache:
            self._cache[key] = self._calc(B, g, B4, B6)
        return self._cache[key]
    def _calc(self, B_ext_z, g_factor, B4, B6):
        m_values = np.arange(s, -s - 1, -1)
        Sz = np.diag(m_values)
        O40 = 60 * np.diag([7, -13, -3, 9, 9, -3, -13, 7])
        X_O44 = np.zeros((8, 8)); X_O44[3, 7] = X_O44[4, 0] = np.sqrt(35); X_O44[2, 6] = X_O44[5, 1] = 5 * np.sqrt(3)
        O44 = 12 * (X_O44 + X_O44.T)
        O60 = 1260 * np.diag([1, -5, 9, -5, -5, 9, -5, 1])
        X_O64 = np.zeros((8, 8)); X_O64[3, 7] = X_O64[4, 0] = 3 * np.sqrt(35); X_O64[2, 6] = X_O64[5, 1] = -7 * np.sqrt(3)
        O64 = 60 * (X_O64 + X_O64.T)
        return (B4 * kB) * (O40 + 5 * O44) + (B6 * kB) * (O60 - 21 * O64) + g_factor * muB * B_ext_z * Sz

_hamiltonian_cache = HamiltonianCache()

def get_hamiltonian_numpy(B, g, B4, B6):
    return _hamiltonian_cache.get(B, g, B4, B6)

def calculate_susceptibility_numpy(omega, H, T, gamma):
    eigenvalues, _ = np.linalg.eigh(H)
    eigenvalues -= np.min(eigenvalues)
    Z = np.sum(np.exp(-eigenvalues / (kB * T)))
    populations = np.exp(-eigenvalues / (kB * T)) / Z
    delta_E = eigenvalues[1:] - eigenvalues[:-1]
    delta_pop = populations[1:] - populations[:-1]
    omega_0 = delta_E / hbar
    m_vals = np.arange(s, -s, -1)
    strength = (s + m_vals) * (s - m_vals + 1)
    
    chi = np.zeros_like(omega, dtype=complex)
    # NumPyç‰ˆã¯ãƒ«ãƒ¼ãƒ—ã§è¨ˆç®—
    for i, w in enumerate(omega):
        denom = omega_0 - w - 1j * gamma
        chi[i] = np.sum(delta_pop * strength / denom)
    return -chi

def calculate_transmission_numpy(omega, mu_r, d, eps_bg):
    eps_mu = eps_bg * mu_r
    # ç°¡æ˜“å®Ÿè£…
    n = np.sqrt(eps_mu + 0j)
    impe = np.sqrt(mu_r / eps_bg + 0j)
    lam = (2*np.pi*c) / omega
    delta = 2*np.pi*n*d/lam
    num = 4*impe
    den = (1+impe)**2 * np.exp(-1j*delta) - (1-impe)**2 * np.exp(1j*delta)
    t = num/den
    return np.abs(t)**2

# =========================================================
# 3. PyTensorç‰ˆ ç‰©ç†é–¢æ•° (Step 2: MCMC/GPUç”¨)
# =========================================================
# ãƒ†ã‚¹ãƒˆæ¸ˆã¿ã®é–¢æ•°ã‚’ã“ã“ã«é…ç½®ã—ã¾ã™

def get_hamiltonian_pt(B_ext_z, g_factor, B4, B6):
    """PyTensorç‰ˆãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³
    
    Parameters
    ----------
    B_ext_z : float or TensorVariable
        å¤–éƒ¨ç£å ´ (T)
    g_factor : float or TensorVariable
        ãƒ©ãƒ³ãƒ‡ã®gå› å­
    B4 : float or TensorVariable
        çµæ™¶å ´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ B4 (K)
    B6 : float or TensorVariable
        çµæ™¶å ´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ B6 (K)
    
    Returns
    -------
    TensorVariable
        ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³è¡Œåˆ— (8x8)
    """
    kB_pt = pt.as_tensor_variable(kB)
    muB_pt = pt.as_tensor_variable(muB)
    m_values = pt.as_tensor_variable(np.arange(s, -s - 1, -1))
    Sz = pt.diag(m_values)
    
    O40_diag = pt.as_tensor_variable([7, -13, -3, 9, 9, -3, -13, 7])
    O40 = pt.as_tensor_variable(60.0) * pt.diag(O40_diag)
    
    X_O44_base = pt.zeros((8, 8))
    v_s35 = np.sqrt(35); v_5s3 = 5 * np.sqrt(3)
    X_O44 = pt.set_subtensor(X_O44_base[3, 7], v_s35)
    X_O44 = pt.set_subtensor(X_O44[4, 0], v_s35)
    X_O44 = pt.set_subtensor(X_O44[2, 6], v_5s3)
    X_O44 = pt.set_subtensor(X_O44[5, 1], v_5s3)
    O44 = pt.as_tensor_variable(12.0) * (X_O44 + X_O44.T) # type: ignore
    
    O60_diag = pt.as_tensor_variable([1, -5, 9, -5, -5, 9, -5, 1])
    O60 = pt.as_tensor_variable(1260.0) * pt.diag(O60_diag)
    
    X_O64_base = pt.zeros((8, 8))
    v_3s35 = 3 * np.sqrt(35); v_m7s3 = -7 * np.sqrt(3)
    X_O64 = pt.set_subtensor(X_O64_base[3, 7], v_3s35)
    X_O64 = pt.set_subtensor(X_O64[4, 0], v_3s35)
    X_O64 = pt.set_subtensor(X_O64[2, 6], v_m7s3)
    X_O64 = pt.set_subtensor(X_O64[5, 1], v_m7s3)
    O64 = pt.as_tensor_variable(60.0) * (X_O64 + X_O64.T) # type: ignore
    
    H_cf = (B4 * kB_pt) * (O40 + 5 * O44) + (B6 * kB_pt) * (O60 - 21 * O64)
    H_zee = g_factor * muB_pt * B_ext_z * Sz
    return H_cf + H_zee

def calculate_susceptibility_pt(omega, H, T, gamma_array):
    """PyTensorç‰ˆç£æ°—æ„Ÿå—ç‡
    
    Parameters
    ----------
    omega : TensorVariable
        è§’å‘¨æ³¢æ•°é…åˆ— (rad/s)
    H : TensorVariable
        ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³è¡Œåˆ— (8x8)
    T : float or TensorVariable
        æ¸©åº¦ (K)
    gamma_array : TensorVariable
        æ¸›è¡°å®šæ•°é…åˆ— (7è¦ç´ )
    
    Returns
    -------
    TensorVariable
        ç£æ°—æ„Ÿå—ç‡ï¼ˆè¤‡ç´ æ•°é…åˆ—ï¼‰
    """
    kB_pt = pt.as_tensor_variable(kB)
    hbar_pt = pt.as_tensor_variable(hbar)
    
    # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®å›ºæœ‰å€¤ã‚’è¨ˆç®—
    eigenvalues, _ = pt.linalg.eigh(H)
    eigenvalues = eigenvalues - pt.min(eigenvalues)
    
    # åˆ†é…é–¢æ•°ã¨å æœ‰ç¢ºç‡
    Z = pt.sum(pt.exp(-eigenvalues / (kB_pt * T)))
    populations = pt.exp(-eigenvalues / (kB_pt * T)) / Z
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼å·®ã¨å æœ‰ç¢ºç‡å·®
    delta_E = eigenvalues[1:] - eigenvalues[:-1]
    delta_pop = populations[1:] - populations[:-1]
    
    # é·ç§»å¼·åº¦
    m_vals = pt.as_tensor_variable(np.arange(s, -s, -1))
    strength = (s + m_vals) * (s - m_vals + 1.0)
    omega_0 = delta_E / hbar_pt
    
    # ç£æ°—æ„Ÿå—ç‡ã®è¨ˆç®—ï¼ˆãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆï¼‰
    numerator = delta_pop * strength
    # ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆè¨ˆç®—
    # omega: (N,), omega_0: (7,), gamma: (7,)
    denom = omega_0[None, :] - omega[:, None] - 1j * gamma_array[None, :]
    chi_comp = numerator[None, :] / denom
    chi = pt.sum(chi_comp, axis=1)
    return -chi

def calculate_transmission_pt(omega, mu_r, d, eps_bg):
    """PyTensorç‰ˆé€éç‡"""
    c_pt = pt.as_tensor_variable(c)
    
    eps_mu = eps_bg * mu_r
    cond = pt.gt(pt.real(eps_mu), 0.0)
    safe_eps_mu = pt.switch(cond, eps_mu, 0.1 + 1j * pt.imag(eps_mu))
    
    n = pt.sqrt(safe_eps_mu + 0j)
    impe = pt.sqrt(mu_r / eps_bg + 0j)
    
    lam = (2 * np.pi * c_pt) / omega
    delta_raw = 2 * np.pi * n * d / lam
    
    # ã‚¯ãƒªãƒƒãƒ—
    d_real = pt.clip(pt.real(delta_raw), -700, 700)
    d_imag = pt.clip(pt.imag(delta_raw), -700, 700)
    delta = d_real + 1j * d_imag
    
    num = 4 * impe
    ep = pt.exp(-1j * delta); en = pt.exp(1j * delta)
    den = (1 + impe)**2 * ep - (1 - impe)**2 * en
    
    t = num / den
    trans = pt.abs(t)**2
    
    # æ­£è¦åŒ–
    t_min = pt.min(trans)
    t_max = pt.max(trans)
    norm = pt.switch(pt.gt(t_max - t_min, 1e-20), (trans - t_min)/(t_max - t_min), 0.5)
    return pt.clip(norm, 0.0, 1.0)

# =========================================================
# 4. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†é–¢æ•°
# =========================================================

def create_frequency_weights(dataset, config):
    # (æ—¢å­˜ã®é‡ã¿ä»˜ã‘ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ä½¿ç”¨)
    # â€»ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã®ãŸã‚ã€å…ƒã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‘¼ã³å‡ºã™ã‹ã€ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„
    # ä¿®æ­£ç‰ˆï¼ˆ1ãƒ”ãƒ¼ã‚¯å¯¾å¿œï¼‰ã‚’å…¥ã‚Œã¦ãŠãã¾ã™
    ws = config['analysis_settings']['weight_settings']
    freq = dataset['frequency']
    trans = dataset['transmittance_full']
    peaks, props = find_peaks(trans, height=ws['peak_height_threshold'], 
                             prominence=ws['peak_prominence_threshold'], 
                             distance=ws['peak_distance'])
    weights = np.full_like(freq, ws['background_weight'])
    
    # ä¿®æ­£ç‰ˆ: 1ãƒ”ãƒ¼ã‚¯ã§ã‚‚é‡ã¿ã‚’ä»˜ã‘ã‚‹
    low_freq_cutoff = config['analysis_settings']['low_freq_cutoff']
    low_peaks = peaks[freq[peaks] < low_freq_cutoff]
    
    # ... (è©³ç´°ãªé‡ã¿ä»˜ã‘ãƒ­ã‚¸ãƒƒã‚¯ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚³ãƒ”ãƒ¼æ¨å¥¨) ...
    # ç°¡æ˜“ç‰ˆã¨ã—ã¦ã€å…¨ãƒ”ãƒ¼ã‚¯å‘¨è¾ºã«é‡ã¿ã‚’ä»˜ã‘ã‚‹å®Ÿè£…ã«ã—ã¾ã™
    widths, _, lefts, rights = peak_widths(trans, peaks, rel_height=0.5)
    left_f = np.interp(lefts, np.arange(len(freq)), freq)
    right_f = np.interp(rights, np.arange(len(freq)), freq)
    
    for i, p in enumerate(peaks):
        mask = (freq >= left_f[i]) & (freq <= right_f[i])
        weights[mask] = ws['lp_up_peak_weight']
        
    return weights

def load_and_prepare_data(config):
    # Excelèª­ã¿è¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯ (Linuxå¯¾å¿œãƒ‘ã‚¹)
    # ç°¡ç•¥åŒ–ã—ã¦è¨˜è¿°ã—ã¾ã™ã€‚å…ƒã® unified_...py ã® load_unified_data ã‚’ä½¿ã£ã¦ãã ã•ã„
    # ã“ã“ã§ã¯ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã ã‘ç¤ºã—ã¾ã™
    # datasets = [{'temperature': 4.0, 'b_field': 9.0, 'frequency': ..., 'transmittance_full': ...}, ...]
    
    # å®Ÿéš›ã®èª­ã¿è¾¼ã¿ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ã®é–¢æ•°ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ã¦ä½¿ã†ã®ãŒå®‰å…¨ã§ã™
    from unified_weighted_bayesian_fitting import load_unified_data as original_loader
    return original_loader(config)

# =========================================================
# 5. Step 1: eps_bg æœ€é©åŒ– (NumPyä½¿ç”¨)
# =========================================================
def fit_eps_bg_step1(datasets, fixed_params, config):
    """Step 1: eps_bg ã¨ d ã®æœ€é©åŒ–ï¼ˆNumPyä½¿ç”¨ï¼‰
    
    Parameters
    ----------
    datasets : list
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒªã‚¹ãƒˆ
    fixed_params : dict
        å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    config : dict
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹
    
    Returns
    -------
    dict
        æ¸©åº¦ã”ã¨ã®æœ€é©åŒ–çµæœ
    
    Notes
    -----
    ã“ã®é–¢æ•°ã¯ç°¡æ˜“å®Ÿè£…ã§ã™ã€‚å®Ÿéš›ã®ä½¿ç”¨ã§ã¯ã€å…ƒã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰
    é©åˆ‡ãªæœ€é©åŒ–é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã‹ã€ã“ã“ã«å®Œå…¨ãªå®Ÿè£…ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
    """
    results = {}
    for ds in datasets:
        temp = ds['temperature']
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        results[temp] = {
            'eps_bg': 14.5,
            'd': 157.8e-6,
            'success': False
        }
        
        print(f"è­¦å‘Š: æ¸©åº¦ {temp}K ã®eps_bgæœ€é©åŒ–ã¯æœªå®Ÿè£…ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰")
    
    return results

# =========================================================
# 6. Step 2: MCMC (PyTensor/GPUä½¿ç”¨) - ãƒ¡ã‚¤ãƒ³æ”¹ä¿®éƒ¨åˆ†
# =========================================================
def run_mcmc_gpu(datasets, eps_bg_map, weights_list, config, model_type, prior_params=None):
    print(f"\nğŸš€ {model_type}ãƒ¢ãƒ‡ãƒ«: GPUãƒ™ã‚¤ã‚ºæ¨å®šã‚’é–‹å§‹ã—ã¾ã™...")
    
    mcmc_conf = config['mcmc']
    
    # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†: PyMCãƒ¢ãƒ‡ãƒ«å†…ã§æ‰±ã„ã‚„ã™ã„ã‚ˆã†ã«çµåˆã™ã‚‹
    # ãŸã ã—ã€Bã‚„TãŒãƒãƒ©ãƒãƒ©ãªã®ã§ã€è¨ˆç®—ã‚°ãƒ©ãƒ•æ§‹ç¯‰æ™‚ã«Pythonãƒ«ãƒ¼ãƒ—ã§å›ã™ã®ãŒä¸€ç•ªç¢ºå®Ÿ
    
    with pm.Model() as model:
        # --- äº‹å‰åˆ†å¸ƒ ---
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ (ç°¡ç•¥åŒ–ã®ãŸã‚ç›´æ¥è¨˜è¿°ä¾‹)
        priors = config['bayesian_priors']['magnetic_parameters']
        
        # å¤‰æ•°å®šç¾© (Opã‚’ä½¿ã‚ãšç›´æ¥å®šç¾©ï¼)
        a_scale = pm.HalfNormal('a_scale', sigma=1.0)
        g_factor = pm.Normal('g_factor', mu=2.0, sigma=0.1)
        B4 = pm.Normal('B4', mu=0.0005, sigma=0.0001)
        B6 = pm.Normal('B6', mu=0.00005, sigma=0.00001)
        
        # Gammaã®å®šç¾© (æ¸©åº¦ä¾å­˜æ€§)
        g_conf = config['bayesian_priors']['gamma_parameters']
        log_gamma_mu_base = pm.Normal('log_gamma_mu_base', mu=25.0, sigma=1.0)
        temp_gamma_slope = pm.Normal('temp_gamma_slope', mu=0.0, sigma=0.01)
        log_gamma_sigma_base = pm.HalfNormal('log_gamma_sigma_base', sigma=0.3)
        log_gamma_offset_base = pm.Normal('log_gamma_offset_base', mu=0.0, sigma=0.3, shape=7)
        
        # --- è¨ˆç®—ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ (ã“ã“ãŒæ–°ã—ã„ï¼) ---
        mu_pred_list = []
        target_data_list = []
        sigma_list = []
        
        base_temp = 4.0
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ãƒ«ãƒ¼ãƒ—ã—ã¦è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’ç¹‹ã
        for i, ds in enumerate(datasets):
            # é‡ã¿ã‚¼ãƒ­ã®ç‚¹ã¯é™¤å¤–ã™ã‚‹å‡¦ç†ãŒå¿…è¦ã ãŒã€
            # JAXã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“ã‚’è€ƒãˆã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¯å›ºå®šã®æ–¹ãŒè‰¯ã„å ´åˆã‚‚ã‚ã‚‹
            # ã“ã“ã§ã¯ã€Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€é‡ã¿ã§å°¤åº¦ã‚’åˆ¶å¾¡ã™ã‚‹ã€æ–¹å¼ã‚’ã¨ã‚‹
            
            # å®šæ•°å…¥åŠ› (PyTensorå®šæ•°åŒ–)
            omega_pt = pt.as_tensor_variable(ds['omega'])
            temp = ds['temperature']
            b_field = ds['b_field']
            
            # 1. Gamma (æ¸©åº¦ä¾å­˜)
            temp_diff = temp - base_temp
            mu_temp = log_gamma_mu_base + temp_gamma_slope * temp_diff
            gamma = pt.exp(mu_temp + log_gamma_offset_base * log_gamma_sigma_base)
            
            # 2. Hamiltonian (ç£å ´ä¾å­˜)
            # b_field ã¯ã‚¹ã‚«ãƒ©å®šæ•°ã¨ã—ã¦æ¸¡ã™
            H = get_hamiltonian_pt(pt.as_tensor_variable(b_field), g_factor, B4, B6)
            
            # 3. Susceptibility
            chi = calculate_susceptibility_pt(omega_pt, H, pt.as_tensor_variable(temp), gamma)
            
            # 4. Transmission
            # G0è¨ˆç®—
            N_spin = config['physical_parameters']['N_spin']
            G0 = a_scale * mu0 * N_spin * (g_factor * muB)**2 / (2 * hbar)
            chi_scaled = G0 * chi
            
            if model_type == 'B_form':
                mu_r = 1.0 / (1.0 - chi_scaled)
            else:
                mu_r = 1.0 + chi_scaled
            
            # å…‰å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Step 1ã®çµæœã‚’ä½¿ç”¨)
            # eps_bg_map ã‹ã‚‰ã“ã®æ¸©åº¦ã®å€¤ã‚’å–å¾—
            opt = eps_bg_map.get(temp, {'eps_bg': 14.2, 'd': 157.8e-6})
            
            trans = calculate_transmission_pt(
                omega_pt, mu_r, 
                pt.as_tensor_variable(opt['d']), 
                pt.as_tensor_variable(opt['eps_bg'])
            )
            
            # ãƒªã‚¹ãƒˆã«è¿½åŠ 
            mu_pred_list.append(trans)
            target_data_list.append(ds['transmittance_full'])
            
            # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ« (é‡ã¿ä»˜ã‘)
            w = weights_list[i]
            # w=0 ã®ã¨ã“ã‚ã¯ sigma=ç„¡é™å¤§ ã«ã—ã¦ç„¡è¦–ã•ã›ã‚‹
            # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã€w < 1e-6 ã®ã¨ã“ã‚ã¯ w=1e-6 æ‰±ã„ã«ã™ã‚‹ç­‰
            w_safe = np.maximum(w, 1e-6)
            sigma_base = pm.HalfNormal(f'sigma_{i}', sigma=0.05) # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’å¤‰ãˆã‚‹ã‹ã€å…±é€šã«ã™ã‚‹ã‹ã¯é¸æŠ
            # ã“ã“ã§ã¯ç°¡å˜ã®ãŸã‚å…±é€šã®sigmaã‚’å®šç¾©ã—ã¦ã‚‚è‰¯ã„
            
            sig = sigma_base / pt.sqrt(pt.as_tensor_variable(w_safe))
            sigma_list.append(sig)
            
        # çµåˆ
        # PyTensorã®concatenateç­‰ã¯ä½¿ã‚ãšã€Observedã‚’å€‹åˆ¥ã«å®šç¾©ã™ã‚‹æ–¹ãŒã‚°ãƒ©ãƒ•æ§‹ç¯‰ãŒè»½ã„å ´åˆã‚‚ã‚ã‚‹ãŒ
        # ã“ã“ã§ã¯ä¸€æ‹¬å®šç¾©ã™ã‚‹
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã®Likelihoodå®šç¾© (ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ãªã©ã§å±•é–‹ã—ã¦ã‚‚è‰¯ã„)
        for i in range(len(datasets)):
             pm.Normal(f'obs_{i}', mu=mu_pred_list[i], sigma=sigma_list[i], observed=target_data_list[i])

        # --- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (GPU/JAX) ---
        print("Sampling using NumPyro (JAX)...")
        # numpyroãŒä½¿ãˆã‚‹å ´åˆ
        try:
            # nuts_sampler='numpyro' ã‚’æŒ‡å®š
            trace = pm.sample(
                draws=mcmc_conf['draws'],
                tune=mcmc_conf['tune'],
                chains=mcmc_conf['chains'],
                nuts_sampler="numpyro", # <--- ã“ã“ãŒé‡è¦ï¼
                random_seed=42
            )
            return trace
        except Exception as e:
            print(f"NumPyro Error: {e}")
            print("Falling back to standard sampler...")
            return pm.sample(draws=1000, tune=500, chains=2)

# =========================================================
# 7. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
# =========================================================
def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    
    GPU/JAXã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¤ã‚ºæ¨å®šã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼:
    1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
    2. eps_bgåˆæœŸå€¤ã®æœ€é©åŒ–
    3. MCMCã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆNumPyro/JAXä½¿ç”¨ï¼‰
    4. çµæœã®ä¿å­˜ã¨å¯è¦–åŒ–
    
    Notes
    -----
    ã“ã®é–¢æ•°ã¯é–‹ç™ºä¸­ã®ãŸã‚ã€ä¸€éƒ¨ã®æ©Ÿèƒ½ã¯æœªå®Ÿè£…ã§ã™ã€‚
    å®Ÿéš›ã®ä½¿ç”¨ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°ãªã©ã®å®Œå…¨ãªå®Ÿè£…ãŒå¿…è¦ã§ã™ã€‚
    """
    print("\n" + "="*70)
    print("GPU/JAXå¯¾å¿œ çµ±åˆãƒ™ã‚¤ã‚ºæ¨å®š é–‹å§‹")
    print("="*70 + "\n")
    
    # è¨­å®šèª­ã¿è¾¼ã¿ã¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    config = load_config()
    results_dir = create_results_directory(config)
    print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {results_dir}\n")
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    try:
        # load_and_prepare_dataã‚’å®Ÿè£…ã™ã‚‹ã‹ã€å…ƒã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰é©åˆ‡ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        datasets_dict = load_and_prepare_data(config)
        
        # æ¸©åº¦å¤‰åŒ–ã¨ç£å ´å¤‰åŒ–ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        datasets = datasets_dict.get('temp_variable', []) + datasets_dict.get('field_variable', [])
        
        if not datasets:
            print("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        print(f"âœ… {len(datasets)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\n")
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # 2. é‡ã¿è¨ˆç®—
    print("âš–ï¸  å‘¨æ³¢æ•°é‡ã¿è¨ˆç®—ä¸­...")
    weights_list = [create_frequency_weights(d, config) for d in datasets]
    print("âœ… é‡ã¿è¨ˆç®—å®Œäº†\n")
    
    # 3. åˆæœŸ eps_bg æœ€é©åŒ– (Step 1)
    print("ğŸ”§ eps_bgåˆæœŸå€¤ã®æœ€é©åŒ–ä¸­...")
    fixed_params = {
        'a_scale': 1.0,
        'g_factor': 2.0,
        'B4': 0.0005,
        'B6': 0.00005
    }
    eps_bg_map = fit_eps_bg_step1(datasets, fixed_params, config)
    print("âœ… eps_bgåˆæœŸå€¤ã®æœ€é©åŒ–å®Œäº†\n")
    
    # 4. MCMCåå¾©ãƒ«ãƒ¼ãƒ—
    max_iterations = config['mcmc'].get('max_iterations', 1)
    for iteration in range(max_iterations):
        print(f"\n{'='*70}")
        print(f"Iteration {iteration+1}/{max_iterations}")
        print(f"{'='*70}\n")
        
        # Step 2: MCMC (GPU/JAX)
        try:
            trace_h = run_mcmc_gpu(datasets, eps_bg_map, weights_list, config, 'H_form')
            
            # çµæœä¿å­˜
            output_path = results_dir / f"trace_H_form_iter{iteration}.nc"
            az.to_netcdf(trace_h, output_path)
            print(f"\nğŸ’¾ ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ä¿å­˜: {output_path.name}")
            
        except Exception as e:
            print(f"âŒ MCMCã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            break
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡º -> eps_bgæ›´æ–° (æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨)
        # TODO: å®Ÿè£…ãŒå¿…è¦
        print("\nâš ï¸  æ³¨æ„: eps_bgæ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ã¯æœªå®Ÿè£…ã§ã™")
        
    print("\n" + "="*70)
    print("ğŸ‰ å‡¦ç†å®Œäº†")
    print("="*70)

if __name__ == "__main__":
    main()