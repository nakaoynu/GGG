"""ä¿å­˜æ¸ˆã¿PyMCãƒˆãƒ¬ãƒ¼ã‚¹ã‹ã‚‰é€éã‚¹ãƒšã‚¯ãƒˆãƒ«ã®95%ä¿¡ç”¨åŒºé–“ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆçµ±åˆç‰ˆï¼‰

unified_weighted_bayesian_fitting.pyã§ç”Ÿæˆã•ã‚ŒãŸä¿å­˜ã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ã€
å„(B, T)ãƒšã‚¢ã§ç£æ°—å¿œç­”ã‚’å†æ§‹æˆã—ã€å¹³å‡é€éç‡ã¨MAPæ¨å®šå€¤ã€95%ä¿¡ç”¨åŒºé–“ã®
ãƒ—ãƒ­ãƒƒãƒˆã¨CSVè¦ç´„ã‚’ä¿å­˜ã—ã¾ã™ã€‚

ã€ä¸»ãªæ©Ÿèƒ½ã€‘
- è¤‡æ•°ã®(B, T)ãƒšã‚¢ã«å¯¾å¿œ
- æ¸©åº¦å¤‰åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ»ç£å ´å¤‰åŒ–ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
- äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰é€éç‡ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®ä¸ç¢ºå®Ÿæ€§ã‚’è¨ˆç®—
- MAPæ¨å®šå€¤ã¨95%ä¿¡ç”¨åŒºé–“ã‚’å¯è¦–åŒ–
"""

from __future__ import annotations

import argparse
import pathlib
import warnings
import datetime
from typing import Dict, Tuple, Any, Optional

import arviz as az
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import xarray as xr
import yaml

import unified_weighted_bayesian_fitting as uwbf

# ç‰©ç†å®šæ•° (SIå˜ä½ç³»)
MU0 = uwbf.mu0
MUB = uwbf.muB
HBAR = uwbf.hbar
KB = uwbf.kB
BASE_TEMPERATURE = 4.0  # æ¸©åº¦ä¾å­˜gammaè¨ˆç®—ã®åŸºæº–æ¸©åº¦
S = uwbf.s # ã‚¹ãƒ”ãƒ³é‡å­æ•°ï¼ˆçµ±åˆç‰ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰å–å¾—ï¼‰
THZ_TO_RAD_S = uwbf.THZ_TO_RAD_S  # THz â†’ rad/s å¤‰æ›ä¿‚æ•°

try:
    import japanize_matplotlib
except ImportError:
    print("è­¦å‘Š: japanize_matplotlib ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

plt.rcParams['figure.dpi'] = 120


def parse_args() -> argparse.Namespace:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ"""
    parser = argparse.ArgumentParser(
        description=(
            "unified_weighted_bayesian_fitting.pyã§ç”Ÿæˆã•ã‚ŒãŸä¿å­˜æ¸ˆã¿PyMCãƒˆãƒ¬ãƒ¼ã‚¹ã‹ã‚‰ã€"
            "é€éã‚¹ãƒšã‚¯ãƒˆãƒ«ã®95%ä¿¡ç”¨åŒºé–“ã‚’è¨ˆç®—ã—ã¾ã™ã€‚"
        )
    )
    parser.add_argument(
        "--results-dir",
        required=True,
        type=pathlib.Path,
        help="trace_<model>.ncã¨è£œåŠ©CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚€å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ãƒ‘ã‚¹",
    )
    parser.add_argument(
        "--model",
        choices=["H_form", "B_form", "both"],
        default="both",
        help="èª­ã¿è¾¼ã‚€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: both, both: ä¸¡ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒ)",
    )
    parser.add_argument(
        "--samples",
        type=int,
        default=300,
        help="äºˆæ¸¬ã‚¹ãƒšã‚¯ãƒˆãƒ«ç”¨ã«æŠ½å‡ºã™ã‚‹äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 300)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«é¸æŠç”¨ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 42)",
    )
    parser.add_argument(
        "--freq-points",
        type=int,
        default=None,
        help=(
            "è©•ä¾¡ç”¨ã®å‘¨æ³¢æ•°ç‚¹æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚çœç•¥ã—ãŸå ´åˆã¯"
            "å…ƒã®å®Ÿé¨“ã‚°ãƒªãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
        ),
    )
    return parser.parse_args()


def load_runtime_config(results_dir: pathlib.Path) -> Dict:
    """ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸè¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
    config_path = results_dir / "config_used.yml"
    if config_path.exists():
        config = uwbf.load_config(config_path)
        print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {config_path}")
    else:
        warnings.warn(
            "config_used.yml ãŒçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® config_unified.yml ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚",
            RuntimeWarning,
            stacklevel=1,
        )
        config = uwbf.load_config()
    return config


def load_unified_data_for_export(config: Dict[str, Any]) -> Dict[Tuple[float, float], Dict[str, Any]]:
    """å…¨(B, T)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã€é‡ã¿é…åˆ—ã‚’ç”Ÿæˆã™ã‚‹"""
    print("\n--- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---")
    
    unified_data = uwbf.load_unified_data(config)
    
    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’(B, T)ã‚­ãƒ¼ã®è¾æ›¸ã«å¤‰æ›
    datasets = {}
    all_datasets = unified_data['temp_variable'] + unified_data['field_variable']
    
    for dataset in all_datasets:
        B = dataset['b_field']
        T = dataset['temperature']
        bt_key = (B, T)
        
        # é‡ã¿é…åˆ—ã‚’ç”Ÿæˆ
        weights = uwbf.create_frequency_weights(dataset, config['analysis_settings'])
        dataset['weights'] = weights
        
        datasets[bt_key] = dataset
        print(f"  èª­ã¿è¾¼ã¿: B={B:.1f}T, T={T:.1f}K (ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(dataset['frequency'])})")
    
    print(f"âœ… åˆè¨ˆ {len(datasets)} å€‹ã®(B, T)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return datasets


def load_bt_parameters(results_dir: pathlib.Path, model_type: str) -> Dict[Tuple[float, float], Dict]:
    """(B, T)ãƒšã‚¢åˆ¥ã®å…‰å­¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’CSVã‹ã‚‰èª­ã¿è¾¼ã‚€"""
    params_path = results_dir / f"bt_optical_parameters_{model_type}.csv"
    if not params_path.exists():
        raise FileNotFoundError(
            f"{model_type} ã®(B, T)ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {params_path}"
        )
    
    df = pd.read_csv(params_path)
    required_cols = {"b_field", "temperature", "eps_bg", "d"}
    missing = required_cols - set(df.columns)
    if missing:
        raise ValueError(
            f"{params_path.name} ã«å¿…é ˆåˆ— {sorted(missing)} ãŒã‚ã‚Šã¾ã›ã‚“"
        )
    
    param_map: Dict[Tuple[float, float], Dict] = {}
    for _, row in df.iterrows():
        b_field = float(row["b_field"])
        temperature = float(row["temperature"])
        bt_key = (b_field, temperature)
        
        param_map[bt_key] = {
            "eps_bg": float(row["eps_bg"]),
            "d": float(row["d"]),
        }
    
    print(f"âœ… {len(param_map)} å€‹ã®(B, T)ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return param_map


def prepare_posterior_samples(
    posterior: xr.Dataset, n_samples: int, seed: int | None
) -> xr.Dataset:
    """äº‹å¾Œåˆ†å¸ƒã‚µãƒ³ãƒ—ãƒ«ã‚’æº–å‚™ï¼ˆè¨ˆç®—åŠ¹ç‡ã®ãŸã‚ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    
    Parameters
    ----------
    posterior : xr.Dataset
        PyMCã®äº‹å¾Œåˆ†å¸ƒ (16,000ã‚µãƒ³ãƒ—ãƒ« = 4000 draws Ã— 4 chains)
    n_samples : int
        æŠ½å‡ºã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•° (æ¨å¥¨: 300)
    seed : int or None
        ä¹±æ•°ã‚·ãƒ¼ãƒ‰
    
    Returns
    -------
    xr.Dataset
        ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸäº‹å¾Œåˆ†å¸ƒ
    """
    posterior_ds = posterior.stack(sample=("chain", "draw"))
    total_samples = posterior_ds.sizes["sample"]
    n_select = min(n_samples, total_samples) if n_samples else total_samples

    print(f"  äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«: {total_samples}å€‹ â†’ {n_select}å€‹ã‚’æŠ½å‡º")

    if n_select < total_samples:
        rng = np.random.default_rng(seed)
        indices = np.sort(rng.choice(total_samples, size=n_select, replace=False))
        subset = posterior_ds.isel(sample=indices)
    else:
        subset = posterior_ds
    return subset


def normalize_transmittance(values: np.ndarray) -> np.ndarray:
    """é€éç‡ãƒ‡ãƒ¼ã‚¿ã‚’0-1ã«æ­£è¦åŒ–"""
    arr = np.asarray(values, dtype=float)
    finite = np.isfinite(arr)
    if not np.any(finite):
        return np.zeros_like(arr)
    arr_finite = arr[finite]
    minimum, maximum = arr_finite.min(), arr_finite.max()
    if maximum > minimum:
        normalized = (arr - minimum) / (maximum - minimum)
    else:
        normalized = np.full_like(arr, 0.5)
    return np.clip(normalized, 0.0, 1.0)


def compute_map_estimates(posterior_subset: xr.Dataset) -> Dict[str, Any]:
    """äº‹å¾Œåˆ†å¸ƒã‹ã‚‰MAPï¼ˆæœ€å¤§äº‹å¾Œç¢ºç‡ï¼‰æ¨å®šå€¤ã‚’è¨ˆç®—
    
    å¯¾ç§°ãªäº‹å¾Œåˆ†å¸ƒã®å ´åˆã€å¹³å‡å€¤ã‚’MAPæ¨å®šå€¤ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚
    """
    map_params: Dict[str, Any] = {
        'a_scale': float(posterior_subset['a_scale'].mean().item()),
        'g_factor': float(posterior_subset['g_factor'].mean().item()),
        'B4': float(posterior_subset['B4'].mean().item()),
        'B6': float(posterior_subset['B6'].mean().item()),
        'log_gamma_mu_base': float(posterior_subset['log_gamma_mu_base'].mean().item()),
        'temp_gamma_slope': float(posterior_subset['temp_gamma_slope'].mean().item()),
        'log_gamma_sigma_base': float(posterior_subset['log_gamma_sigma_base'].mean().item()),
        'log_gamma_offset_base': posterior_subset['log_gamma_offset_base'].mean(dim='sample').values,
    }
    return map_params


def calculate_transmission_single(
    freq_thz_array: np.ndarray,
    b_field: float,
    temperature: float,
    eps_bg: float,
    thickness: float,
    a_scale: float,
    g_factor: float,
    param_b4: float,
    param_b6: float,
    gamma_array: np.ndarray,
    model_type: str,
    n_spin: float,
    S: float = S,
) -> np.ndarray:
    """å˜ä¸€ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é€éã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ï¼ˆTHzå˜ä½ç³»å¯¾å¿œç‰ˆï¼‰
    
    Parameters
    ----------
    freq_thz_array : np.ndarray
        å‘¨æ³¢æ•°é…åˆ— (THz)
    b_field : float
        ç£å ´ (T)
    temperature : float
        æ¸©åº¦ (K)
    eps_bg : float
        èƒŒæ™¯èª˜é›»ç‡
    thickness : float
        è©¦æ–™åšã• (m)
    a_scale : float
        ç£æ°—æ„Ÿå—ç‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°
    g_factor : float
        ãƒ©ãƒ³ãƒ‡ã®gå› å­
    param_b4 : float
        çµæ™¶å ´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ B4 (K)
    param_b6 : float
        çµæ™¶å ´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ B6 (K)
    gamma_array : np.ndarray
        é·ç§»ã®æ¸›è¡°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é…åˆ— (THz)
    model_type : str
        ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— ('H_form' ã¾ãŸã¯ 'B_form')
    n_spin : float
        ã‚¹ãƒ”ãƒ³å¯†åº¦ (m^-3)
    s : float
        ã‚¹ãƒ”ãƒ³é‡å­æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3.5)
    
    Returns
    -------
    np.ndarray
        æ­£è¦åŒ–ã•ã‚ŒãŸé€éã‚¹ãƒšã‚¯ãƒˆãƒ«
    """
    # ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã‚’è¨ˆç®—
    hamiltonian = uwbf.get_hamiltonian(b_field, g_factor, param_b4, param_b6)
    
    # ç£æ°—æ„Ÿå—ç‡ã‚’è¨ˆç®—ï¼ˆTHzå˜ä½ç³»ï¼‰
    chi_raw = uwbf.calculate_susceptibility(freq_thz_array, hamiltonian, temperature, gamma_array)
    # ã€ä¿®æ­£ã€‘THzå˜ä½ç³»ã§ã®æ¬¡å…ƒåˆã‚ã›: chi_rawã¯1/THzæ¬¡å…ƒ = THZ_TO_RAD_S/(rad/s)
    # æ—§ç‰ˆã®chi_rawã¯1/(rad/s)æ¬¡å…ƒãªã®ã§ã€chi_raw_new = chi_raw_old * THZ_TO_RAD_S
    # chi = G0 * chi_raw ã‚’ä¸€è‡´ã•ã›ã‚‹ã«ã¯ G0_new = G0_old / THZ_TO_RAD_S
    g0 = a_scale * MU0 * n_spin * (g_factor * MUB) ** 2 / (2 * HBAR) / THZ_TO_RAD_S
    chi = g0 * chi_raw

    # ãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ã¦æ¯”é€ç£ç‡ã‚’è¨ˆç®—
    if model_type == "B_form":
        mu_r = 1.0 / (1.0 - chi)
    else:  # H_form
        mu_r = 1.0 + chi

    # é€éç‡ã‚’è¨ˆç®—ï¼ˆTHzå˜ä½ç³»ï¼‰
    trans = uwbf.calculate_normalized_transmission(freq_thz_array, mu_r, thickness, eps_bg)
    return np.clip(np.real_if_close(trans), 0.0, 1.0)


def simulate_predictions(
    dataset: Dict[str, Any],
    b_field: float,
    temperature: float,
    params: Dict[str, float],
    posterior_subset: xr.Dataset,
    model_type: str,
    n_spin: float,
    s: float,
    freq_points: int | None,
) -> Dict[str, np.ndarray]:
    """äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰é€éç‡ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®äºˆæ¸¬ã‚’è¨ˆç®—
    
    Parameters
    ----------
    dataset : Dict
        å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    b_field : float
        ç£å ´ (T)
    temperature : float
        æ¸©åº¦ (K)
    params : Dict
        eps_bg, d ãªã©ã®(B, T)å›ºæœ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    posterior_subset : xr.Dataset
        äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«ã®ã‚µãƒ–ã‚»ãƒƒãƒˆ
    model_type : str
        ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
    n_spin : float
        ã‚¹ãƒ”ãƒ³å¯†åº¦
    s : float
        ã‚¹ãƒ”ãƒ³é‡å­æ•°
    freq_points : int or None
        è©•ä¾¡ã™ã‚‹å‘¨æ³¢æ•°ç‚¹æ•°
    
    Returns
    -------
    Dict[str, np.ndarray]
        å‘¨æ³¢æ•°ã€å¹³å‡ã€MAPã€ä¿¡ç”¨åŒºé–“ã€å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸
    """
    freq_exp = np.asarray(dataset["frequency"], dtype=float)
    if freq_points and freq_points > 0:
        freq_eval = np.linspace(freq_exp.min(), freq_exp.max(), freq_points)
    else:
        freq_eval = freq_exp

    eps_bg = params["eps_bg"]
    thickness = params["d"]

    # äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
    a_scale = np.asarray(posterior_subset["a_scale"].values, dtype=float)
    g_factor = np.asarray(posterior_subset["g_factor"].values, dtype=float)
    param_b4 = np.asarray(posterior_subset["B4"].values, dtype=float)
    param_b6 = np.asarray(posterior_subset["B6"].values, dtype=float)
    log_gamma_mu = np.asarray(posterior_subset["log_gamma_mu_base"].values, dtype=float)
    temp_gamma_slope = np.asarray(posterior_subset["temp_gamma_slope"].values, dtype=float)
    log_gamma_sigma = np.asarray(posterior_subset["log_gamma_sigma_base"].values, dtype=float)
    log_gamma_offset = np.asarray(posterior_subset["log_gamma_offset_base"].values, dtype=float)

    n_draws = a_scale.shape[0]
    predictions = np.zeros((n_draws, freq_eval.size), dtype=float)

    # æ¸©åº¦ä¾å­˜gammaã‚’è¨ˆç®—
    temp_diff = temperature - BASE_TEMPERATURE
    log_gamma_mu_temp = log_gamma_mu + temp_gamma_slope * temp_diff
    
    # log_gamma_offsetã®å½¢çŠ¶ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ
    if log_gamma_offset.ndim == 1:
        # 1æ¬¡å…ƒã®å ´åˆ: (7,) â†’ (n_draws, 7)
        gamma_samples = np.exp(
            log_gamma_mu_temp[:, None] + log_gamma_offset[None, :] * log_gamma_sigma[:, None]
        )
    elif log_gamma_offset.shape[0] == 7:
        # å½¢çŠ¶ãŒ (7, n_draws) ã®å ´åˆ â†’ è»¢ç½®ã—ã¦ (n_draws, 7)
        log_gamma_offset_T = log_gamma_offset.T
        gamma_samples = np.exp(
            log_gamma_mu_temp[:, None] + log_gamma_offset_T * log_gamma_sigma[:, None]
        )
    else:
        # å½¢çŠ¶ãŒ (n_draws, 7) ã®å ´åˆ
        gamma_samples = np.exp(
            log_gamma_mu_temp[:, None] + log_gamma_offset * log_gamma_sigma[:, None]
        )

    # å…¨äº‹å¾Œã‚µãƒ³ãƒ—ãƒ«ã§é€éç‡ã‚’è¨ˆç®—ï¼ˆTHzå˜ä½ç³»ï¼‰
    print(f"    äº‹å¾Œã‚µãƒ³ãƒ—ãƒ« {n_draws}å€‹ã§é€éç‡ã‚’è¨ˆç®—ä¸­...", end="", flush=True)
    
    # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã‚’è¡¨ç¤º
    if n_draws > 0:
        print(f"\n    [ãƒ‡ãƒãƒƒã‚°] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¾‹ (sample 0):")
        print(f"      a_scale={a_scale[0]:.4f}, g_factor={g_factor[0]:.4f}")
        print(f"      B4={param_b4[0]:.6f} K, B6={param_b6[0]:.8f} K")
        print(f"      gamma (THz): {gamma_samples[0][:3]}... (æœ€åˆã®3ã¤)")
        print(f"      eps_bg={eps_bg:.4f}, thickness={thickness*1e6:.2f} um")
        print(f"    ", end="", flush=True)
    
    for idx in range(n_draws):
        predictions[idx] = calculate_transmission_single(
            freq_eval, b_field, temperature, eps_bg, thickness,
            a_scale[idx], g_factor[idx], param_b4[idx], param_b6[idx],
            gamma_samples[idx], model_type, n_spin, s
        )
    print(" å®Œäº†")
    
    # ãƒ‡ãƒãƒƒã‚°: äºˆæ¸¬å€¤ã®çµ±è¨ˆã‚’è¡¨ç¤º
    pred_mean = predictions.mean()
    pred_std = predictions.std()
    pred_all_same = np.allclose(predictions, 0.5, atol=0.01)
    if pred_all_same:
        print(f"    [è­¦å‘Š] äºˆæ¸¬ãŒå…¨ã¦0.5ä»˜è¿‘: ç‰©ç†ãƒ¢ãƒ‡ãƒ«è¨ˆç®—ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§")
    else:
        print(f"    [ãƒ‡ãƒãƒƒã‚°] äºˆæ¸¬çµ±è¨ˆ: mean={pred_mean:.4f}, std={pred_std:.4f}, range=[{predictions.min():.4f}, {predictions.max():.4f}]")

    # çµ±è¨ˆé‡ã‚’è¨ˆç®—
    mean_pred = predictions.mean(axis=0)
    lower, upper = np.percentile(predictions, [2.5, 97.5], axis=0)

    # MAPï¼ˆæœ€å¤§äº‹å¾Œç¢ºç‡ï¼‰äºˆæ¸¬ã‚’è¨ˆç®—ï¼ˆTHzå˜ä½ç³»ï¼‰
    map_params = compute_map_estimates(posterior_subset)
    temp_diff_map = temperature - BASE_TEMPERATURE
    log_gamma_mu_temp_map = map_params['log_gamma_mu_base'] + map_params['temp_gamma_slope'] * temp_diff_map
    gamma_map = np.exp(
        log_gamma_mu_temp_map + map_params['log_gamma_offset_base'] * map_params['log_gamma_sigma_base']
    )
    
    map_pred = calculate_transmission_single(
        freq_eval, b_field, temperature, eps_bg, thickness,
        map_params['a_scale'], map_params['g_factor'], map_params['B4'], map_params['B6'],
        gamma_map, model_type, n_spin, s
    )

    # é‡ã¿æƒ…å ±ã‚‚è¿”ã™
    weights = dataset.get("weights", np.ones_like(freq_eval))
    
    return {
        "frequency_thz": freq_eval,
        "mean": mean_pred,
        "map": map_pred,
        "lower": lower,
        "upper": upper,
        "observed": normalize_transmittance(dataset.get("transmittance_full", freq_eval * 0.0)),
        "weights": weights,
    }


def save_outputs(
    output_dir: pathlib.Path,
    model_type: str,
    b_field: float,
    temperature: float,
    summary: Dict[str, np.ndarray],
) -> None:
    """çµæœã‚’CSVã¨PNGã§ä¿å­˜"""
    freq = summary["frequency_thz"]
    df = pd.DataFrame(
        {
            "frequency_thz": freq,
            "mean_transmission": summary["mean"],
            "map_transmission": summary["map"],
            "lower_95": summary["lower"],
            "upper_95": summary["upper"],
            "observed_normalized": summary["observed"],
        }
    )
    csv_path = output_dir / f"transmission_ci_{model_type}_B{b_field:.1f}T_T{int(temperature)}K.csv"
    df.to_csv(csv_path, index=False)

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.fill_between(freq, summary["lower"], summary["upper"], 
                     color="tab:blue", alpha=0.3, label="95%ä¿¡ç”¨åŒºé–“")
    ax.plot(freq, summary["mean"], color="tab:blue", linewidth=2.0, 
            label="äº‹å¾Œå¹³å‡", linestyle='--')
    ax.plot(freq, summary["map"], color="tab:red", linewidth=2.5, 
            label="MAPæ¨å®šå€¤")
    
    # é‡ã¿æƒ…å ±ãŒã‚ã‚‹å ´åˆã€é‡ã¿ã«å¿œã˜ã¦è‰²åˆ†ã‘ã—ã¦è¡¨ç¤º
    weights = summary.get("weights", np.ones_like(freq))
    mask_weight_1 = np.abs(weights - 1.0) < 1e-6
    mask_weight_mid = np.abs(weights - 0.1) < 1e-6
    mask_weight_other = ~(mask_weight_1 | mask_weight_mid)
    
    if np.any(mask_weight_other):
        ax.scatter(freq[mask_weight_other], summary["observed"][mask_weight_other], 
                  color="lightgray", s=12, alpha=0.5, label="å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿(èƒŒæ™¯)", zorder=3)
    if np.any(mask_weight_mid):
        ax.scatter(freq[mask_weight_mid], summary["observed"][mask_weight_mid], 
                  color="orange", s=16, alpha=0.7, label="å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿(LP-UPé–“)", zorder=4)
    if np.any(mask_weight_1):
        ax.scatter(freq[mask_weight_1], summary["observed"][mask_weight_1], 
                  color="black", s=20, alpha=0.8, label="å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿(ãƒ”ãƒ¼ã‚¯)", zorder=5)
    
    ax.set_xlabel("å‘¨æ³¢æ•° (THz)")
    ax.set_ylabel("æ­£è¦åŒ–é€éç‡")
    ax.set_title(f"{model_type} é€éã‚¹ãƒšã‚¯ãƒˆãƒ« @ B={b_field:.1f}T, T={temperature:.0f}K")
    ax.grid(True, linestyle="--", alpha=0.5)
    ax.set_ylim(0.0, 1.05)
    ax.legend()
    png_path = output_dir / f"transmission_ci_{model_type}_B{b_field:.1f}T_T{int(temperature)}K.png"
    fig.tight_layout()
    fig.savefig(png_path, dpi=300)
    plt.close(fig)


def save_comparison_outputs(
    output_dir: pathlib.Path,
    b_field: float,
    temperature: float,
    summary_h: Dict[str, np.ndarray],
    summary_b: Dict[str, np.ndarray],
    config: Dict[str, Any],
) -> None:
    """H_formã¨B_formã®æ¯”è¼ƒçµæœã‚’CSVã¨PNGã§ä¿å­˜"""
    freq = summary_h["frequency_thz"]
    
    # æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ä¿å­˜
    df = pd.DataFrame(
        {
            "frequency_thz": freq,
            "H_form_mean": summary_h["mean"],
            "H_form_map": summary_h["map"],
            "H_form_lower_95": summary_h["lower"],
            "H_form_upper_95": summary_h["upper"],
            "B_form_mean": summary_b["mean"],
            "B_form_map": summary_b["map"],
            "B_form_lower_95": summary_b["lower"],
            "B_form_upper_95": summary_b["upper"],
            "observed_normalized": summary_h["observed"],
        }
    )
    csv_path = output_dir / f"transmission_comparison_B{b_field:.1f}T_T{int(temperature)}K.csv"
    df.to_csv(csv_path, index=False)

    # æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)
    
    # ä¸Šæ®µ: ä¸¡ãƒ¢ãƒ‡ãƒ«ã®MAPæ¨å®šå€¤ã¨å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
    ax1.fill_between(freq, summary_h["lower"], summary_h["upper"], 
                     color="tab:red", alpha=0.2, label="H_form 95%ä¿¡ç”¨åŒºé–“")
    ax1.fill_between(freq, summary_b["lower"], summary_b["upper"], 
                     color="tab:blue", alpha=0.2, label="B_form 95%ä¿¡ç”¨åŒºé–“")
    ax1.plot(freq, summary_h["map"], color="tab:red", linewidth=2.5, 
             label="H_form MAPæ¨å®šå€¤", linestyle='-')
    ax1.plot(freq, summary_b["map"], color="tab:blue", linewidth=2.5, 
             label="B_form MAPæ¨å®šå€¤", linestyle='-')
    
    # é‡ã¿æƒ…å ±ãŒã‚ã‚‹å ´åˆã€é‡ã¿ã«å¿œã˜ã¦è‰²åˆ†ã‘ã—ã¦è¡¨ç¤º
    weight_settings = config['analysis_settings'].get('weight_settings', {})
    w_high = float(weight_settings['lp_up_peak_weight'])
    w_mid = float(weight_settings['between_peaks_weight'])
    
    weights = summary_h.get("weights", np.ones_like(freq))
    mask_weight_1 = np.abs(weights - w_high) < 1e-6
    mask_weight_mid = np.abs(weights - w_mid) < 1e-6
    mask_weight_other = ~(mask_weight_1 | mask_weight_mid)
    
    if np.any(mask_weight_other):
        ax1.scatter(freq[mask_weight_other], summary_h["observed"][mask_weight_other], 
                   color="lightgray", s=12, alpha=0.5, label="å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿(èƒŒæ™¯)", zorder=3)
    if np.any(mask_weight_mid):
        ax1.scatter(freq[mask_weight_mid], summary_h["observed"][mask_weight_mid], 
                   color="orange", s=16, alpha=0.7, label=f"å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿(LP-UPé–“ w={w_mid})", zorder=4)
    if np.any(mask_weight_1):
        ax1.scatter(freq[mask_weight_1], summary_h["observed"][mask_weight_1], 
                   color="black", s=20, alpha=0.8, label=f"å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿(ãƒ”ãƒ¼ã‚¯ w={w_high})", zorder=5)
    
    ax1.set_ylabel("æ­£è¦åŒ–é€éç‡")
    ax1.set_title(f"ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ: é€éã‚¹ãƒšã‚¯ãƒˆãƒ« @ B={b_field:.1f}T, T={temperature:.0f}K")
    ax1.grid(True, linestyle="--", alpha=0.5)
    ax1.set_ylim(0.0, 1.05)
    ax1.legend(loc='best', fontsize=9)
    
    # ä¸‹æ®µ: ä¸¡ãƒ¢ãƒ‡ãƒ«ã®å·®åˆ†ï¼ˆH_form - B_formï¼‰
    diff_map = summary_h["map"] - summary_b["map"]
    diff_mean = summary_h["mean"] - summary_b["mean"]
    ax2.plot(freq, diff_map, color="tab:green", linewidth=2.0, 
             label="MAPå·®åˆ† (H_form - B_form)")
    ax2.plot(freq, diff_mean, color="tab:orange", linewidth=1.5, 
             linestyle='--', label="å¹³å‡å·®åˆ† (H_form - B_form)")
    ax2.axhline(y=0, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)
    ax2.set_xlabel("å‘¨æ³¢æ•° (THz)")
    ax2.set_ylabel("é€éç‡å·®åˆ†")
    ax2.set_title("ãƒ¢ãƒ‡ãƒ«é–“å·®åˆ†")
    ax2.grid(True, linestyle="--", alpha=0.5)
    ax2.legend(loc='best', fontsize=9)
    
    png_path = output_dir / f"transmission_comparison_B{b_field:.1f}T_T{int(temperature)}K.png"
    fig.tight_layout()
    fig.savefig(png_path, dpi=300)
    plt.close(fig)
    print(f"    æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜: {png_path.name}")


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    args = parse_args()
    results_dir = args.results_dir.expanduser().resolve()
    if not results_dir.exists():
        raise FileNotFoundError(f"çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {results_dir}")

    print("="*70)
    print("çµ±åˆç‰ˆ: é€éã‚¹ãƒšã‚¯ãƒˆãƒ«95%ä¿¡ç”¨åŒºé–“ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print("="*70)
    print(f"çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {results_dir}")
    print(f"ãƒ¢ãƒ‡ãƒ«: {args.model}")
    print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {args.samples}")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    config = load_runtime_config(results_dir)

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿
    datasets = load_unified_data_for_export(config)
    
    # ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
    n_spin = config['physical_parameters']['N_spin']
    s = config['physical_parameters']['s']
    
    # ä¸¡ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
    if args.model == "both":
        print("\n=== ä¸¡ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰ ===")
        
        # ä¸¡ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        models_data = {}
        for model_type in ["H_form", "B_form"]:
            trace_path = results_dir / f"trace_{model_type}.nc"
            if not trace_path.exists():
                raise FileNotFoundError(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {trace_path}")
            
            print(f"\nğŸ“‚ {model_type} ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            trace = az.from_netcdf(trace_path)
            posterior_subset = prepare_posterior_samples(trace.posterior, args.samples, args.seed)  # type: ignore[attr-defined]
            bt_params = load_bt_parameters(results_dir, model_type)
            
            models_data[model_type] = {
                'posterior_subset': posterior_subset,
                'bt_params': bt_params,
            }
        
        output_dir = results_dir / "transmission_intervals_comparison"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ“ å‡ºåŠ›å…ˆ: {output_dir}")
        
        missing_bt = []
        for bt_key in sorted(datasets.keys()):
            B, T = bt_key
            
            # ä¸¡ãƒ¢ãƒ‡ãƒ«ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if (bt_key not in models_data["H_form"]['bt_params'] or
                bt_key not in models_data["B_form"]['bt_params']):
                missing_bt.append(bt_key)
                continue
            
            print(f"\n  å‡¦ç†ä¸­: B={B:.1f}T, T={T:.1f}K")
            
            # H_formã®äºˆæ¸¬ã‚’è¨ˆç®—
            summary_h = simulate_predictions(
                dataset=datasets[bt_key],
                b_field=B,
                temperature=T,
                params=models_data["H_form"]['bt_params'][bt_key],
                posterior_subset=models_data["H_form"]['posterior_subset'],
                model_type="H_form",
                n_spin=n_spin,
                s=s,
                freq_points=args.freq_points,
            )
            
            # B_formã®äºˆæ¸¬ã‚’è¨ˆç®—
            summary_b = simulate_predictions(
                dataset=datasets[bt_key],
                b_field=B,
                temperature=T,
                params=models_data["B_form"]['bt_params'][bt_key],
                posterior_subset=models_data["B_form"]['posterior_subset'],
                model_type="B_form",
                n_spin=n_spin,
                s=s,
                freq_points=args.freq_points,
            )
            
            # æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜
            save_comparison_outputs(output_dir, B, T, summary_h, summary_b, config)
            
            # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚‚ä¿å­˜
            save_outputs(output_dir, "H_form", B, T, summary_h)
            save_outputs(output_dir, "B_form", B, T, summary_b)
            
            print(f"    âœ… B={B:.1f}T, T={T:.1f}K ã®æ¯”è¼ƒçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        
        if missing_bt:
            warnings.warn(
                "ä»¥ä¸‹ã®(B, T)ãƒšã‚¢ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: "
                + ", ".join(f"({B:.1f}T, {T:.0f}K)" for B, T in missing_bt),
                RuntimeWarning,
                stacklevel=1,
            )
        
        print(f"\nğŸ‰ å…¨ã¦ã®æ¯”è¼ƒå‡ºåŠ›ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_dir}")
    
    # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
    else:
        print(f"\n=== {args.model} ãƒ¢ãƒ‡ãƒ«å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ ===")
        
        # ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        trace_path = results_dir / f"trace_{args.model}.nc"
        if not trace_path.exists():
            raise FileNotFoundError(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {trace_path}")
        
        print(f"\nğŸ“‚ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        trace = az.from_netcdf(trace_path)
        posterior_subset = prepare_posterior_samples(trace.posterior, args.samples, args.seed)  # type: ignore[attr-defined]
        bt_params = load_bt_parameters(results_dir, args.model)

        output_dir = results_dir / f"transmission_intervals_{args.model}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ“ å‡ºåŠ›å…ˆ: {output_dir}")

        missing_bt = []
        for bt_key in sorted(datasets.keys()):
            B, T = bt_key
            
            if bt_key not in bt_params:
                missing_bt.append(bt_key)
                continue
            
            print(f"\n  å‡¦ç†ä¸­: B={B:.1f}T, T={T:.1f}K")
            
            summary = simulate_predictions(
                dataset=datasets[bt_key],
                b_field=B,
                temperature=T,
                params=bt_params[bt_key],
                posterior_subset=posterior_subset,
                model_type=args.model,
                n_spin=n_spin,
                s=s,
                freq_points=args.freq_points,
            )
            save_outputs(output_dir, args.model, B, T, summary)
            print(f"    âœ… B={B:.1f}T, T={T:.1f}K ã®é€éã‚¹ãƒšã‚¯ãƒˆãƒ«ä¿¡ç”¨åŒºé–“ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

        if missing_bt:
            warnings.warn(
                "ä»¥ä¸‹ã®(B, T)ãƒšã‚¢ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: "
                + ", ".join(f"({B:.1f}T, {T:.0f}K)" for B, T in missing_bt),
                RuntimeWarning,
                stacklevel=1,
            )

        print(f"\nğŸ‰ å…¨ã¦ã®å‡ºåŠ›ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_dir}")


if __name__ == "__main__":
    main()
